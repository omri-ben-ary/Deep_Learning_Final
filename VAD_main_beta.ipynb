{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04bb3860-f4ed-4dc2-bb65-fd5bab45d709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from VariationalAutoDecoder_Beta import VariationalAutoDecoder as VAD_beta\n",
    "from VAD_Trainer import VAD_Trainer\n",
    "import utils\n",
    "from evaluate import evaluate_model\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d227682-fe2c-4635-8f22-43695ac358ee",
   "metadata": {},
   "source": [
    "## Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb85c21c-5862-401b-88a4-e20796edf5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, train_dl, test_ds, test_dl = utils.create_dataloaders(data_path=\"dataset\" ,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c9b43a-4434-4820-92c0-caf522961bb1",
   "metadata": {},
   "source": [
    "## Train Auto Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb06f910-ca78-4244-9055-91cfcf343f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dims = [16, 32, 64, 128]\n",
    "betas = [1e5, 5e5, 1e6, 5e6]\n",
    "VADs = [VAD_beta(latent_dim=dim, device=device) for (dim,_) in list(itertools.product(latent_dims, betas))]\n",
    "trainers = [VAD_Trainer(var_decoder=VADs[i], dataloader=train_dl, latent_dim=dim, beta=beta, device=device, lr=1e-3)\n",
    "            for i,(dim,beta) in enumerate(list(itertools.product(latent_dims, betas)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13baccde-a05f-4922-b4b9-681d7aecfc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = len(train_dl.dataset)\n",
    "csv_file_path = 'results_VAD_beta.csv'\n",
    "\n",
    "with open(csv_file_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    header = ['Index'] + [f'Epoch {i+1} Loss' for i in range(500)] + ['Final Train Loss']\n",
    "    writer.writerow(header)\n",
    "\n",
    "for index, trainer in enumerate(trainers):\n",
    "    optimizer = optim.Adam([trainer.latents], lr=1e-3)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_loss = trainer.train(num_epochs=500)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Trainer {index} has finished training in {elapsed_time:.2f} seconds.\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_eval_loss = evaluate_model(model=VADs[index], test_dl=train_dl, opt=optimizer, latents=trainer.latents, epochs=500, device=device) \n",
    "    end_time = time.time()\n",
    "    \n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"AD {index} has finished train evaluation in {elapsed_time:.2f} seconds.\")\n",
    "\n",
    "    row = [index] + train_loss + [train_eval_loss]\n",
    "\n",
    "    with open(csv_file_path, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"Results saved to {csv_file_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27147e64-6c63-4528-bc12-99750ba8ccae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(trainers)):\n",
    "    latents = VADs[i].reparameterize(trainers[i].latents)\n",
    "    utils.plot_tsne(train_ds, latents, f\"tsne_beta_{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd033aaf-061c-4bd6-b32e-40466dd1027f",
   "metadata": {},
   "source": [
    "## Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc862a48-c47c-49ce-b233-71192301ee15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 737387140.0000\n",
      "Epoch [2/1000], Loss: 721309380.0000\n",
      "Epoch [3/1000], Loss: 709920924.0000\n",
      "Epoch [4/1000], Loss: 699624148.0000\n",
      "Epoch [5/1000], Loss: 689984576.0000\n",
      "Epoch [6/1000], Loss: 680849784.0000\n",
      "Epoch [7/1000], Loss: 672122528.0000\n",
      "Epoch [8/1000], Loss: 663770336.0000\n",
      "Epoch [9/1000], Loss: 655746940.0000\n",
      "Epoch [10/1000], Loss: 648035284.0000\n",
      "Epoch [11/1000], Loss: 640625144.0000\n",
      "Epoch [12/1000], Loss: 633442164.0000\n",
      "Epoch [13/1000], Loss: 626515792.0000\n",
      "Epoch [14/1000], Loss: 619782800.0000\n",
      "Epoch [15/1000], Loss: 613240316.0000\n",
      "Epoch [16/1000], Loss: 606896524.0000\n",
      "Epoch [17/1000], Loss: 600614800.0000\n",
      "Epoch [18/1000], Loss: 594600188.0000\n",
      "Epoch [19/1000], Loss: 588616332.0000\n",
      "Epoch [20/1000], Loss: 582789664.0000\n",
      "Epoch [21/1000], Loss: 577118968.0000\n",
      "Epoch [22/1000], Loss: 571475804.0000\n",
      "Epoch [23/1000], Loss: 565994424.0000\n",
      "Epoch [24/1000], Loss: 560607668.0000\n",
      "Epoch [25/1000], Loss: 555250032.0000\n",
      "Epoch [26/1000], Loss: 550079596.0000\n",
      "Epoch [27/1000], Loss: 544897364.0000\n",
      "Epoch [28/1000], Loss: 539873970.0000\n",
      "Epoch [29/1000], Loss: 534907980.0000\n",
      "Epoch [30/1000], Loss: 530014674.0000\n",
      "Epoch [31/1000], Loss: 525171672.0000\n",
      "Epoch [32/1000], Loss: 520431398.0000\n",
      "Epoch [33/1000], Loss: 515746422.0000\n",
      "Epoch [34/1000], Loss: 511116164.0000\n",
      "Epoch [35/1000], Loss: 506558626.0000\n",
      "Epoch [36/1000], Loss: 502089058.0000\n",
      "Epoch [37/1000], Loss: 497656606.0000\n",
      "Epoch [38/1000], Loss: 493246156.0000\n",
      "Epoch [39/1000], Loss: 488932170.0000\n",
      "Epoch [40/1000], Loss: 484682112.0000\n",
      "Epoch [41/1000], Loss: 480487412.0000\n",
      "Epoch [42/1000], Loss: 476312488.0000\n",
      "Epoch [43/1000], Loss: 472259554.0000\n",
      "Epoch [44/1000], Loss: 468203016.0000\n",
      "Epoch [45/1000], Loss: 464215588.0000\n",
      "Epoch [46/1000], Loss: 460248046.0000\n",
      "Epoch [47/1000], Loss: 456341846.0000\n",
      "Epoch [48/1000], Loss: 452508562.0000\n",
      "Epoch [49/1000], Loss: 448669258.0000\n",
      "Epoch [50/1000], Loss: 444923872.0000\n",
      "Epoch [51/1000], Loss: 441155142.0000\n",
      "Epoch [52/1000], Loss: 437497266.0000\n",
      "Epoch [53/1000], Loss: 433859824.0000\n",
      "Epoch [54/1000], Loss: 430266670.0000\n",
      "Epoch [55/1000], Loss: 426671558.0000\n",
      "Epoch [56/1000], Loss: 423158450.0000\n",
      "Epoch [57/1000], Loss: 419691512.0000\n",
      "Epoch [58/1000], Loss: 416213392.0000\n",
      "Epoch [59/1000], Loss: 412813792.0000\n",
      "Epoch [60/1000], Loss: 409430166.0000\n",
      "Epoch [61/1000], Loss: 406096042.0000\n",
      "Epoch [62/1000], Loss: 402753908.0000\n",
      "Epoch [63/1000], Loss: 399528822.0000\n",
      "Epoch [64/1000], Loss: 396275566.0000\n",
      "Epoch [65/1000], Loss: 393095888.0000\n",
      "Epoch [66/1000], Loss: 389887488.0000\n",
      "Epoch [67/1000], Loss: 386756594.0000\n",
      "Epoch [68/1000], Loss: 383607650.0000\n",
      "Epoch [69/1000], Loss: 380546696.0000\n",
      "Epoch [70/1000], Loss: 377547886.0000\n",
      "Epoch [71/1000], Loss: 374491050.0000\n",
      "Epoch [72/1000], Loss: 371487848.0000\n",
      "Epoch [73/1000], Loss: 368571410.0000\n",
      "Epoch [74/1000], Loss: 365615616.0000\n",
      "Epoch [75/1000], Loss: 362653696.0000\n",
      "Epoch [76/1000], Loss: 359784434.0000\n",
      "Epoch [77/1000], Loss: 356934622.0000\n",
      "Epoch [78/1000], Loss: 354100234.0000\n",
      "Epoch [79/1000], Loss: 351345520.0000\n",
      "Epoch [80/1000], Loss: 348572144.0000\n",
      "Epoch [81/1000], Loss: 345843518.0000\n",
      "Epoch [82/1000], Loss: 343085122.0000\n",
      "Epoch [83/1000], Loss: 340450776.0000\n",
      "Epoch [84/1000], Loss: 337739776.0000\n",
      "Epoch [85/1000], Loss: 335124662.0000\n",
      "Epoch [86/1000], Loss: 332462638.0000\n",
      "Epoch [87/1000], Loss: 329854564.0000\n",
      "Epoch [88/1000], Loss: 327315086.0000\n",
      "Epoch [89/1000], Loss: 324683356.0000\n",
      "Epoch [90/1000], Loss: 322168362.0000\n",
      "Epoch [91/1000], Loss: 319713858.0000\n",
      "Epoch [92/1000], Loss: 317218334.0000\n",
      "Epoch [93/1000], Loss: 314737578.0000\n",
      "Epoch [94/1000], Loss: 312324382.0000\n",
      "Epoch [95/1000], Loss: 309876778.0000\n",
      "Epoch [96/1000], Loss: 307490934.0000\n",
      "Epoch [97/1000], Loss: 305089658.0000\n",
      "Epoch [98/1000], Loss: 302735922.0000\n",
      "Epoch [99/1000], Loss: 300415266.0000\n",
      "Epoch [100/1000], Loss: 298058314.0000\n",
      "Epoch [101/1000], Loss: 295761416.0000\n",
      "Epoch [102/1000], Loss: 293486350.0000\n",
      "Epoch [103/1000], Loss: 291264746.0000\n",
      "Epoch [104/1000], Loss: 289034052.0000\n",
      "Epoch [105/1000], Loss: 286809646.0000\n",
      "Epoch [106/1000], Loss: 284560476.0000\n",
      "Epoch [107/1000], Loss: 282496838.0000\n",
      "Epoch [108/1000], Loss: 280200316.0000\n",
      "Epoch [109/1000], Loss: 278124038.0000\n",
      "Epoch [110/1000], Loss: 275981550.0000\n",
      "Epoch [111/1000], Loss: 273857578.0000\n",
      "Epoch [112/1000], Loss: 271795986.0000\n",
      "Epoch [113/1000], Loss: 269668435.0000\n",
      "Epoch [114/1000], Loss: 267626836.0000\n",
      "Epoch [115/1000], Loss: 265585755.0000\n",
      "Epoch [116/1000], Loss: 263558934.0000\n",
      "Epoch [117/1000], Loss: 261439653.0000\n",
      "Epoch [118/1000], Loss: 259558167.0000\n",
      "Epoch [119/1000], Loss: 257533363.0000\n",
      "Epoch [120/1000], Loss: 255585730.0000\n",
      "Epoch [121/1000], Loss: 253658619.0000\n",
      "Epoch [122/1000], Loss: 251727238.0000\n",
      "Epoch [123/1000], Loss: 249822730.0000\n",
      "Epoch [124/1000], Loss: 247917802.0000\n",
      "Epoch [125/1000], Loss: 246011736.0000\n",
      "Epoch [126/1000], Loss: 244138518.0000\n",
      "Epoch [127/1000], Loss: 242275355.0000\n",
      "Epoch [128/1000], Loss: 240469843.0000\n",
      "Epoch [129/1000], Loss: 238664172.0000\n",
      "Epoch [130/1000], Loss: 236820156.0000\n",
      "Epoch [131/1000], Loss: 235004171.0000\n",
      "Epoch [132/1000], Loss: 233216527.0000\n",
      "Epoch [133/1000], Loss: 231463926.0000\n",
      "Epoch [134/1000], Loss: 229704815.0000\n",
      "Epoch [135/1000], Loss: 227936016.0000\n",
      "Epoch [136/1000], Loss: 226249521.0000\n",
      "Epoch [137/1000], Loss: 224564702.0000\n",
      "Epoch [138/1000], Loss: 222819465.0000\n",
      "Epoch [139/1000], Loss: 221134790.0000\n",
      "Epoch [140/1000], Loss: 219462178.0000\n",
      "Epoch [141/1000], Loss: 217774647.0000\n",
      "Epoch [142/1000], Loss: 216190736.0000\n",
      "Epoch [143/1000], Loss: 214495806.0000\n",
      "Epoch [144/1000], Loss: 212935208.0000\n",
      "Epoch [145/1000], Loss: 211262422.0000\n",
      "Epoch [146/1000], Loss: 209733850.0000\n",
      "Epoch [147/1000], Loss: 208118593.0000\n",
      "Epoch [148/1000], Loss: 206517048.0000\n",
      "Epoch [149/1000], Loss: 204978273.0000\n",
      "Epoch [150/1000], Loss: 203426139.0000\n",
      "Epoch [151/1000], Loss: 201884737.0000\n",
      "Epoch [152/1000], Loss: 200395886.0000\n",
      "Epoch [153/1000], Loss: 198863001.0000\n",
      "Epoch [154/1000], Loss: 197308724.0000\n",
      "Epoch [155/1000], Loss: 195893405.0000\n",
      "Epoch [156/1000], Loss: 194348668.0000\n",
      "Epoch [157/1000], Loss: 192902962.0000\n",
      "Epoch [158/1000], Loss: 191438436.0000\n",
      "Epoch [159/1000], Loss: 189960578.0000\n",
      "Epoch [160/1000], Loss: 188555602.0000\n",
      "Epoch [161/1000], Loss: 187156659.0000\n",
      "Epoch [162/1000], Loss: 185710514.0000\n",
      "Epoch [163/1000], Loss: 184304356.0000\n",
      "Epoch [164/1000], Loss: 182873257.0000\n",
      "Epoch [165/1000], Loss: 181538589.0000\n",
      "Epoch [166/1000], Loss: 180142102.0000\n",
      "Epoch [167/1000], Loss: 178835845.0000\n",
      "Epoch [168/1000], Loss: 177419546.0000\n",
      "Epoch [169/1000], Loss: 176148134.0000\n",
      "Epoch [170/1000], Loss: 174790195.0000\n",
      "Epoch [171/1000], Loss: 173453985.0000\n",
      "Epoch [172/1000], Loss: 172156221.0000\n",
      "Epoch [173/1000], Loss: 170816989.0000\n",
      "Epoch [174/1000], Loss: 169519305.0000\n",
      "Epoch [175/1000], Loss: 168286578.0000\n",
      "Epoch [176/1000], Loss: 166986035.0000\n",
      "Epoch [177/1000], Loss: 165693579.0000\n",
      "Epoch [178/1000], Loss: 164489542.0000\n",
      "Epoch [179/1000], Loss: 163216552.0000\n",
      "Epoch [180/1000], Loss: 162043824.0000\n",
      "Epoch [181/1000], Loss: 160790945.0000\n",
      "Epoch [182/1000], Loss: 159580879.0000\n",
      "Epoch [183/1000], Loss: 158311464.0000\n",
      "Epoch [184/1000], Loss: 157109513.0000\n",
      "Epoch [185/1000], Loss: 155949243.0000\n",
      "Epoch [186/1000], Loss: 154736846.0000\n",
      "Epoch [187/1000], Loss: 153605484.0000\n",
      "Epoch [188/1000], Loss: 152427665.0000\n",
      "Epoch [189/1000], Loss: 151270070.0000\n",
      "Epoch [190/1000], Loss: 150128563.0000\n",
      "Epoch [191/1000], Loss: 148982096.0000\n",
      "Epoch [192/1000], Loss: 147839790.0000\n",
      "Epoch [193/1000], Loss: 146715094.0000\n",
      "Epoch [194/1000], Loss: 145613005.0000\n",
      "Epoch [195/1000], Loss: 144518623.0000\n",
      "Epoch [196/1000], Loss: 143399135.0000\n",
      "Epoch [197/1000], Loss: 142347658.0000\n",
      "Epoch [198/1000], Loss: 141213047.0000\n",
      "Epoch [199/1000], Loss: 140149293.0000\n",
      "Epoch [200/1000], Loss: 139106398.0000\n",
      "Epoch [201/1000], Loss: 138044951.0000\n",
      "Epoch [202/1000], Loss: 136966075.5000\n",
      "Epoch [203/1000], Loss: 135927078.0000\n",
      "Epoch [204/1000], Loss: 134970875.0000\n",
      "Epoch [205/1000], Loss: 133852008.0000\n",
      "Epoch [206/1000], Loss: 132891861.5000\n",
      "Epoch [207/1000], Loss: 131850237.5000\n",
      "Epoch [208/1000], Loss: 130855406.5000\n",
      "Epoch [209/1000], Loss: 129850079.0000\n",
      "Epoch [210/1000], Loss: 128882682.5000\n",
      "Epoch [211/1000], Loss: 127847642.0000\n",
      "Epoch [212/1000], Loss: 126866666.0000\n",
      "Epoch [213/1000], Loss: 125924624.5000\n",
      "Epoch [214/1000], Loss: 124977895.5000\n",
      "Epoch [215/1000], Loss: 124026582.5000\n",
      "Epoch [216/1000], Loss: 123068979.0000\n",
      "Epoch [217/1000], Loss: 122125594.0000\n",
      "Epoch [218/1000], Loss: 121192671.0000\n",
      "Epoch [219/1000], Loss: 120316216.5000\n",
      "Epoch [220/1000], Loss: 119341370.5000\n",
      "Epoch [221/1000], Loss: 118441039.5000\n",
      "Epoch [222/1000], Loss: 117501877.0000\n",
      "Epoch [223/1000], Loss: 116597495.0000\n",
      "Epoch [224/1000], Loss: 115724117.5000\n",
      "Epoch [225/1000], Loss: 114852884.0000\n",
      "Epoch [226/1000], Loss: 113945473.0000\n",
      "Epoch [227/1000], Loss: 113101796.5000\n",
      "Epoch [228/1000], Loss: 112213784.0000\n",
      "Epoch [229/1000], Loss: 111365631.0000\n",
      "Epoch [230/1000], Loss: 110492397.0000\n",
      "Epoch [231/1000], Loss: 109665306.0000\n",
      "Epoch [232/1000], Loss: 108801333.5000\n",
      "Epoch [233/1000], Loss: 107985283.0000\n",
      "Epoch [234/1000], Loss: 107165854.0000\n",
      "Epoch [235/1000], Loss: 106343702.0000\n",
      "Epoch [236/1000], Loss: 105514780.5000\n",
      "Epoch [237/1000], Loss: 104689777.0000\n",
      "Epoch [238/1000], Loss: 103914049.5000\n",
      "Epoch [239/1000], Loss: 103061827.0000\n",
      "Epoch [240/1000], Loss: 102336439.5000\n",
      "Epoch [241/1000], Loss: 101507796.5000\n",
      "Epoch [242/1000], Loss: 100759336.0000\n",
      "Epoch [243/1000], Loss: 99961543.0000\n",
      "Epoch [244/1000], Loss: 99177371.0000\n",
      "Epoch [245/1000], Loss: 98402876.0000\n",
      "Epoch [246/1000], Loss: 97688743.0000\n",
      "Epoch [247/1000], Loss: 96918874.0000\n",
      "Epoch [248/1000], Loss: 96144678.0000\n",
      "Epoch [249/1000], Loss: 95417401.5000\n",
      "Epoch [250/1000], Loss: 94680527.5000\n",
      "Epoch [251/1000], Loss: 93928080.0000\n",
      "Epoch [252/1000], Loss: 93213450.5000\n",
      "Epoch [253/1000], Loss: 92492678.0000\n",
      "Epoch [254/1000], Loss: 91814605.5000\n",
      "Epoch [255/1000], Loss: 91074542.0000\n",
      "Epoch [256/1000], Loss: 90357752.5000\n",
      "Epoch [257/1000], Loss: 89663506.0000\n",
      "Epoch [258/1000], Loss: 88989268.0000\n",
      "Epoch [259/1000], Loss: 88278463.5000\n",
      "Epoch [260/1000], Loss: 87575725.0000\n",
      "Epoch [261/1000], Loss: 86909714.0000\n",
      "Epoch [262/1000], Loss: 86255110.0000\n",
      "Epoch [263/1000], Loss: 85562517.0000\n",
      "Epoch [264/1000], Loss: 84953948.0000\n",
      "Epoch [265/1000], Loss: 84277487.5000\n",
      "Epoch [266/1000], Loss: 83624787.5000\n",
      "Epoch [267/1000], Loss: 82940423.5000\n",
      "Epoch [268/1000], Loss: 82298633.0000\n",
      "Epoch [269/1000], Loss: 81697350.5000\n",
      "Epoch [270/1000], Loss: 80993360.5000\n",
      "Epoch [271/1000], Loss: 80378601.0000\n",
      "Epoch [272/1000], Loss: 79789319.5000\n",
      "Epoch [273/1000], Loss: 79153797.5000\n",
      "Epoch [274/1000], Loss: 78529543.0000\n",
      "Epoch [275/1000], Loss: 77930757.5000\n",
      "Epoch [276/1000], Loss: 77307153.0000\n",
      "Epoch [277/1000], Loss: 76719412.5000\n",
      "Epoch [278/1000], Loss: 76167907.0000\n",
      "Epoch [279/1000], Loss: 75507407.5000\n",
      "Epoch [280/1000], Loss: 74947853.5000\n",
      "Epoch [281/1000], Loss: 74333423.5000\n",
      "Epoch [282/1000], Loss: 73786254.0000\n",
      "Epoch [283/1000], Loss: 73216325.5000\n",
      "Epoch [284/1000], Loss: 72636916.5000\n",
      "Epoch [285/1000], Loss: 72082898.0000\n",
      "Epoch [286/1000], Loss: 71491346.0000\n",
      "Epoch [287/1000], Loss: 70963125.0000\n",
      "Epoch [288/1000], Loss: 70389693.0000\n",
      "Epoch [289/1000], Loss: 69856904.0000\n",
      "Epoch [290/1000], Loss: 69278624.2500\n",
      "Epoch [291/1000], Loss: 68788055.2500\n",
      "Epoch [292/1000], Loss: 68218837.7500\n",
      "Epoch [293/1000], Loss: 67718315.7500\n",
      "Epoch [294/1000], Loss: 67167143.0000\n",
      "Epoch [295/1000], Loss: 66592801.7500\n",
      "Epoch [296/1000], Loss: 66112397.0000\n",
      "Epoch [297/1000], Loss: 65596843.0000\n",
      "Epoch [298/1000], Loss: 65065313.2500\n",
      "Epoch [299/1000], Loss: 64570390.2500\n",
      "Epoch [300/1000], Loss: 64061423.7500\n",
      "Epoch [301/1000], Loss: 63560348.2500\n",
      "Epoch [302/1000], Loss: 63058442.5000\n",
      "Epoch [303/1000], Loss: 62581210.7500\n",
      "Epoch [304/1000], Loss: 62107858.5000\n",
      "Epoch [305/1000], Loss: 61610712.2500\n",
      "Epoch [306/1000], Loss: 61127251.0000\n",
      "Epoch [307/1000], Loss: 60642298.2500\n",
      "Epoch [308/1000], Loss: 60159218.5000\n",
      "Epoch [309/1000], Loss: 59732895.7500\n",
      "Epoch [310/1000], Loss: 59215690.7500\n",
      "Epoch [311/1000], Loss: 58745649.2500\n",
      "Epoch [312/1000], Loss: 58291324.7500\n",
      "Epoch [313/1000], Loss: 57871775.7500\n",
      "Epoch [314/1000], Loss: 57365678.0000\n",
      "Epoch [315/1000], Loss: 56911184.0000\n",
      "Epoch [316/1000], Loss: 56498490.2500\n",
      "Epoch [317/1000], Loss: 56060158.0000\n",
      "Epoch [318/1000], Loss: 55606960.7500\n",
      "Epoch [319/1000], Loss: 55184234.2500\n",
      "Epoch [320/1000], Loss: 54716049.7500\n",
      "Epoch [321/1000], Loss: 54324592.2500\n",
      "Epoch [322/1000], Loss: 53886907.5000\n",
      "Epoch [323/1000], Loss: 53450304.5000\n",
      "Epoch [324/1000], Loss: 53051551.5000\n",
      "Epoch [325/1000], Loss: 52633777.5000\n",
      "Epoch [326/1000], Loss: 52222627.7500\n",
      "Epoch [327/1000], Loss: 51772357.2500\n",
      "Epoch [328/1000], Loss: 51423029.0000\n",
      "Epoch [329/1000], Loss: 51000956.7500\n",
      "Epoch [330/1000], Loss: 50597566.5000\n",
      "Epoch [331/1000], Loss: 50198900.2500\n",
      "Epoch [332/1000], Loss: 49805119.0000\n",
      "Epoch [333/1000], Loss: 49437263.7500\n",
      "Epoch [334/1000], Loss: 49025333.7500\n",
      "Epoch [335/1000], Loss: 48641183.7500\n",
      "Epoch [336/1000], Loss: 48264031.7500\n",
      "Epoch [337/1000], Loss: 47867717.7500\n",
      "Epoch [338/1000], Loss: 47480185.0000\n",
      "Epoch [339/1000], Loss: 47137540.2500\n",
      "Epoch [340/1000], Loss: 46765246.0000\n",
      "Epoch [341/1000], Loss: 46404082.0000\n",
      "Epoch [342/1000], Loss: 46043928.5000\n",
      "Epoch [343/1000], Loss: 45666823.5000\n",
      "Epoch [344/1000], Loss: 45282466.5000\n",
      "Epoch [345/1000], Loss: 44952939.7500\n",
      "Epoch [346/1000], Loss: 44615900.7500\n",
      "Epoch [347/1000], Loss: 44290540.7500\n",
      "Epoch [348/1000], Loss: 43888662.5000\n",
      "Epoch [349/1000], Loss: 43593605.5000\n",
      "Epoch [350/1000], Loss: 43225201.0000\n",
      "Epoch [351/1000], Loss: 42888847.5000\n",
      "Epoch [352/1000], Loss: 42555436.7500\n",
      "Epoch [353/1000], Loss: 42204116.5000\n",
      "Epoch [354/1000], Loss: 41884095.7500\n",
      "Epoch [355/1000], Loss: 41539999.2500\n",
      "Epoch [356/1000], Loss: 41253969.7500\n",
      "Epoch [357/1000], Loss: 40906768.5000\n",
      "Epoch [358/1000], Loss: 40576724.0000\n",
      "Epoch [359/1000], Loss: 40291745.7500\n",
      "Epoch [360/1000], Loss: 39957432.2500\n",
      "Epoch [361/1000], Loss: 39637054.7500\n",
      "Epoch [362/1000], Loss: 39334899.7500\n",
      "Epoch [363/1000], Loss: 39022700.5000\n",
      "Epoch [364/1000], Loss: 38718005.2500\n",
      "Epoch [365/1000], Loss: 38410323.2500\n",
      "Epoch [366/1000], Loss: 38103822.0000\n",
      "Epoch [367/1000], Loss: 37804864.2500\n",
      "Epoch [368/1000], Loss: 37552331.2500\n",
      "Epoch [369/1000], Loss: 37253053.5000\n",
      "Epoch [370/1000], Loss: 36934552.0000\n",
      "Epoch [371/1000], Loss: 36668660.0000\n",
      "Epoch [372/1000], Loss: 36358121.0000\n",
      "Epoch [373/1000], Loss: 36100094.5000\n",
      "Epoch [374/1000], Loss: 35796880.5000\n",
      "Epoch [375/1000], Loss: 35515756.0000\n",
      "Epoch [376/1000], Loss: 35241195.3750\n",
      "Epoch [377/1000], Loss: 34972958.3750\n",
      "Epoch [378/1000], Loss: 34722692.7500\n",
      "Epoch [379/1000], Loss: 34418985.8750\n",
      "Epoch [380/1000], Loss: 34155956.3750\n",
      "Epoch [381/1000], Loss: 33919412.2500\n",
      "Epoch [382/1000], Loss: 33626767.6250\n",
      "Epoch [383/1000], Loss: 33376273.8750\n",
      "Epoch [384/1000], Loss: 33130963.3750\n",
      "Epoch [385/1000], Loss: 32884871.1250\n",
      "Epoch [386/1000], Loss: 32628432.5000\n",
      "Epoch [387/1000], Loss: 32347899.1250\n",
      "Epoch [388/1000], Loss: 32105930.7500\n",
      "Epoch [389/1000], Loss: 31841582.1250\n",
      "Epoch [390/1000], Loss: 31607493.8750\n",
      "Epoch [391/1000], Loss: 31366565.0000\n",
      "Epoch [392/1000], Loss: 31108923.8750\n",
      "Epoch [393/1000], Loss: 30873572.2500\n",
      "Epoch [394/1000], Loss: 30652850.7500\n",
      "Epoch [395/1000], Loss: 30424087.6250\n",
      "Epoch [396/1000], Loss: 30170175.2500\n",
      "Epoch [397/1000], Loss: 29934718.1250\n",
      "Epoch [398/1000], Loss: 29712365.5000\n",
      "Epoch [399/1000], Loss: 29506857.3750\n",
      "Epoch [400/1000], Loss: 29266876.8750\n",
      "Epoch [401/1000], Loss: 29041101.1250\n",
      "Epoch [402/1000], Loss: 28803494.8750\n",
      "Epoch [403/1000], Loss: 28595057.0000\n",
      "Epoch [404/1000], Loss: 28375192.5000\n",
      "Epoch [405/1000], Loss: 28159030.3750\n",
      "Epoch [406/1000], Loss: 27939383.1250\n",
      "Epoch [407/1000], Loss: 27727688.8750\n",
      "Epoch [408/1000], Loss: 27511041.0000\n",
      "Epoch [409/1000], Loss: 27276761.7500\n",
      "Epoch [410/1000], Loss: 27097623.2500\n",
      "Epoch [411/1000], Loss: 26880206.3750\n",
      "Epoch [412/1000], Loss: 26682202.6250\n",
      "Epoch [413/1000], Loss: 26479850.7500\n",
      "Epoch [414/1000], Loss: 26267397.8750\n",
      "Epoch [415/1000], Loss: 26070852.8750\n",
      "Epoch [416/1000], Loss: 25873488.5000\n",
      "Epoch [417/1000], Loss: 25697967.1250\n",
      "Epoch [418/1000], Loss: 25501047.8750\n",
      "Epoch [419/1000], Loss: 25287509.6250\n",
      "Epoch [420/1000], Loss: 25098858.5000\n",
      "Epoch [421/1000], Loss: 24913899.5000\n",
      "Epoch [422/1000], Loss: 24722130.1250\n",
      "Epoch [423/1000], Loss: 24540449.3750\n",
      "Epoch [424/1000], Loss: 24352910.6250\n",
      "Epoch [425/1000], Loss: 24165163.6250\n",
      "Epoch [426/1000], Loss: 23972981.2500\n",
      "Epoch [427/1000], Loss: 23809312.8750\n",
      "Epoch [428/1000], Loss: 23623205.6250\n",
      "Epoch [429/1000], Loss: 23447129.2500\n",
      "Epoch [430/1000], Loss: 23279734.2500\n",
      "Epoch [431/1000], Loss: 23097651.2500\n",
      "Epoch [432/1000], Loss: 22920973.5000\n",
      "Epoch [433/1000], Loss: 22759678.3750\n",
      "Epoch [434/1000], Loss: 22567978.6250\n",
      "Epoch [435/1000], Loss: 22443116.6250\n",
      "Epoch [436/1000], Loss: 22242277.8750\n",
      "Epoch [437/1000], Loss: 22081911.6250\n",
      "Epoch [438/1000], Loss: 21933663.2500\n",
      "Epoch [439/1000], Loss: 21752347.3750\n",
      "Epoch [440/1000], Loss: 21591190.0000\n",
      "Epoch [441/1000], Loss: 21442486.0000\n",
      "Epoch [442/1000], Loss: 21285081.3750\n",
      "Epoch [443/1000], Loss: 21121921.7500\n",
      "Epoch [444/1000], Loss: 20978150.6250\n",
      "Epoch [445/1000], Loss: 20802893.3750\n",
      "Epoch [446/1000], Loss: 20660010.2500\n",
      "Epoch [447/1000], Loss: 20486705.7500\n",
      "Epoch [448/1000], Loss: 20357806.3750\n",
      "Epoch [449/1000], Loss: 20214694.6250\n",
      "Epoch [450/1000], Loss: 20053046.7500\n",
      "Epoch [451/1000], Loss: 19917817.3750\n",
      "Epoch [452/1000], Loss: 19770274.8750\n",
      "Epoch [453/1000], Loss: 19626190.3750\n",
      "Epoch [454/1000], Loss: 19483328.1250\n",
      "Epoch [455/1000], Loss: 19339473.7500\n",
      "Epoch [456/1000], Loss: 19195360.0000\n",
      "Epoch [457/1000], Loss: 19058199.6250\n",
      "Epoch [458/1000], Loss: 18921622.7500\n",
      "Epoch [459/1000], Loss: 18786314.7500\n",
      "Epoch [460/1000], Loss: 18657734.8750\n",
      "Epoch [461/1000], Loss: 18509823.6250\n",
      "Epoch [462/1000], Loss: 18394021.0000\n",
      "Epoch [463/1000], Loss: 18254803.7500\n",
      "Epoch [464/1000], Loss: 18124061.3750\n",
      "Epoch [465/1000], Loss: 17983070.7500\n",
      "Epoch [466/1000], Loss: 17861108.2500\n",
      "Epoch [467/1000], Loss: 17726766.5000\n",
      "Epoch [468/1000], Loss: 17597651.1875\n",
      "Epoch [469/1000], Loss: 17479248.4375\n",
      "Epoch [470/1000], Loss: 17359878.0625\n",
      "Epoch [471/1000], Loss: 17226823.3750\n",
      "Epoch [472/1000], Loss: 17113177.2500\n",
      "Epoch [473/1000], Loss: 16997341.0625\n",
      "Epoch [474/1000], Loss: 16861193.6250\n",
      "Epoch [475/1000], Loss: 16756521.4375\n",
      "Epoch [476/1000], Loss: 16644873.7500\n",
      "Epoch [477/1000], Loss: 16514175.7500\n",
      "Epoch [478/1000], Loss: 16405426.8125\n",
      "Epoch [479/1000], Loss: 16285991.5625\n",
      "Epoch [480/1000], Loss: 16171436.9375\n",
      "Epoch [481/1000], Loss: 16067983.8750\n",
      "Epoch [482/1000], Loss: 15953431.6250\n",
      "Epoch [483/1000], Loss: 15835467.1250\n",
      "Epoch [484/1000], Loss: 15731643.6250\n",
      "Epoch [485/1000], Loss: 15617951.3125\n",
      "Epoch [486/1000], Loss: 15501012.6875\n",
      "Epoch [487/1000], Loss: 15393465.6875\n",
      "Epoch [488/1000], Loss: 15298160.8750\n",
      "Epoch [489/1000], Loss: 15192206.5000\n",
      "Epoch [490/1000], Loss: 15074673.0000\n",
      "Epoch [491/1000], Loss: 14976775.6875\n",
      "Epoch [492/1000], Loss: 14873984.8125\n",
      "Epoch [493/1000], Loss: 14791736.0000\n",
      "Epoch [494/1000], Loss: 14679019.8125\n",
      "Epoch [495/1000], Loss: 14589824.9375\n",
      "Epoch [496/1000], Loss: 14494284.9375\n",
      "Epoch [497/1000], Loss: 14385285.7500\n",
      "Epoch [498/1000], Loss: 14287132.1875\n",
      "Epoch [499/1000], Loss: 14196170.7500\n",
      "Epoch [500/1000], Loss: 14100132.7500\n",
      "Epoch [501/1000], Loss: 13992611.4375\n",
      "Epoch [502/1000], Loss: 13910923.2500\n",
      "Epoch [503/1000], Loss: 13817053.3750\n",
      "Epoch [504/1000], Loss: 13722563.1250\n",
      "Epoch [505/1000], Loss: 13620952.3750\n",
      "Epoch [506/1000], Loss: 13553542.9375\n",
      "Epoch [507/1000], Loss: 13445284.0625\n",
      "Epoch [508/1000], Loss: 13366126.3750\n",
      "Epoch [509/1000], Loss: 13296364.5625\n",
      "Epoch [510/1000], Loss: 13191461.5000\n",
      "Epoch [511/1000], Loss: 13096758.1875\n",
      "Epoch [512/1000], Loss: 13018798.1250\n",
      "Epoch [513/1000], Loss: 12941922.6875\n",
      "Epoch [514/1000], Loss: 12845292.0625\n",
      "Epoch [515/1000], Loss: 12776706.2500\n",
      "Epoch [516/1000], Loss: 12682642.3125\n",
      "Epoch [517/1000], Loss: 12606334.3750\n",
      "Epoch [518/1000], Loss: 12525439.0000\n",
      "Epoch [519/1000], Loss: 12447616.4375\n",
      "Epoch [520/1000], Loss: 12366822.4375\n",
      "Epoch [521/1000], Loss: 12296657.2500\n",
      "Epoch [522/1000], Loss: 12219810.2500\n",
      "Epoch [523/1000], Loss: 12126388.2500\n",
      "Epoch [524/1000], Loss: 12059378.6875\n",
      "Epoch [525/1000], Loss: 11974549.9375\n",
      "Epoch [526/1000], Loss: 11897375.6875\n",
      "Epoch [527/1000], Loss: 11831626.1250\n",
      "Epoch [528/1000], Loss: 11742606.8750\n",
      "Epoch [529/1000], Loss: 11678342.0000\n",
      "Epoch [530/1000], Loss: 11621610.5625\n",
      "Epoch [531/1000], Loss: 11528410.0000\n",
      "Epoch [532/1000], Loss: 11470671.0000\n",
      "Epoch [533/1000], Loss: 11409697.0625\n",
      "Epoch [534/1000], Loss: 11334852.3125\n",
      "Epoch [535/1000], Loss: 11256779.3125\n",
      "Epoch [536/1000], Loss: 11189389.0000\n",
      "Epoch [537/1000], Loss: 11117612.1875\n",
      "Epoch [538/1000], Loss: 11051971.9375\n",
      "Epoch [539/1000], Loss: 10988944.9375\n",
      "Epoch [540/1000], Loss: 10919603.1875\n",
      "Epoch [541/1000], Loss: 10866494.1250\n",
      "Epoch [542/1000], Loss: 10784621.6250\n",
      "Epoch [543/1000], Loss: 10737383.8125\n",
      "Epoch [544/1000], Loss: 10659679.5000\n",
      "Epoch [545/1000], Loss: 10606160.1250\n",
      "Epoch [546/1000], Loss: 10542114.2500\n",
      "Epoch [547/1000], Loss: 10477947.5000\n",
      "Epoch [548/1000], Loss: 10431431.6250\n",
      "Epoch [549/1000], Loss: 10359967.8125\n",
      "Epoch [550/1000], Loss: 10301397.5000\n",
      "Epoch [551/1000], Loss: 10239768.0000\n",
      "Epoch [552/1000], Loss: 10175386.8750\n",
      "Epoch [553/1000], Loss: 10127442.5000\n",
      "Epoch [554/1000], Loss: 10065146.6875\n",
      "Epoch [555/1000], Loss: 9995601.1250\n",
      "Epoch [556/1000], Loss: 9944832.4375\n",
      "Epoch [557/1000], Loss: 9885072.8125\n",
      "Epoch [558/1000], Loss: 9827991.5000\n",
      "Epoch [559/1000], Loss: 9781031.1875\n",
      "Epoch [560/1000], Loss: 9726264.2500\n",
      "Epoch [561/1000], Loss: 9674683.5625\n",
      "Epoch [562/1000], Loss: 9618010.7500\n",
      "Epoch [563/1000], Loss: 9571674.1875\n",
      "Epoch [564/1000], Loss: 9514653.1250\n",
      "Epoch [565/1000], Loss: 9454293.1250\n",
      "Epoch [566/1000], Loss: 9406944.5625\n",
      "Epoch [567/1000], Loss: 9353244.0000\n",
      "Epoch [568/1000], Loss: 9306254.6250\n",
      "Epoch [569/1000], Loss: 9252283.6875\n",
      "Epoch [570/1000], Loss: 9199045.5000\n",
      "Epoch [571/1000], Loss: 9151924.3125\n",
      "Epoch [572/1000], Loss: 9102436.7500\n",
      "Epoch [573/1000], Loss: 9063547.9375\n",
      "Epoch [574/1000], Loss: 9016133.5625\n",
      "Epoch [575/1000], Loss: 8964305.6250\n",
      "Epoch [576/1000], Loss: 8915153.1562\n",
      "Epoch [577/1000], Loss: 8871857.0938\n",
      "Epoch [578/1000], Loss: 8823462.1250\n",
      "Epoch [579/1000], Loss: 8783523.7188\n",
      "Epoch [580/1000], Loss: 8733582.0312\n",
      "Epoch [581/1000], Loss: 8688547.1250\n",
      "Epoch [582/1000], Loss: 8641771.3438\n",
      "Epoch [583/1000], Loss: 8597760.5625\n",
      "Epoch [584/1000], Loss: 8548436.8438\n",
      "Epoch [585/1000], Loss: 8508431.9062\n",
      "Epoch [586/1000], Loss: 8475393.4688\n",
      "Epoch [587/1000], Loss: 8424001.0312\n",
      "Epoch [588/1000], Loss: 8385675.3438\n",
      "Epoch [589/1000], Loss: 8336501.0938\n",
      "Epoch [590/1000], Loss: 8301829.9062\n",
      "Epoch [591/1000], Loss: 8257402.1250\n",
      "Epoch [592/1000], Loss: 8219688.3750\n",
      "Epoch [593/1000], Loss: 8176289.5312\n",
      "Epoch [594/1000], Loss: 8144695.2500\n",
      "Epoch [595/1000], Loss: 8094565.2812\n",
      "Epoch [596/1000], Loss: 8051577.7812\n",
      "Epoch [597/1000], Loss: 8024817.8438\n",
      "Epoch [598/1000], Loss: 7990861.0312\n",
      "Epoch [599/1000], Loss: 7955814.2500\n",
      "Epoch [600/1000], Loss: 7915823.2812\n",
      "Epoch [601/1000], Loss: 7862452.0000\n",
      "Epoch [602/1000], Loss: 7838599.3438\n",
      "Epoch [603/1000], Loss: 7805018.9688\n",
      "Epoch [604/1000], Loss: 7767000.8750\n",
      "Epoch [605/1000], Loss: 7733964.9688\n",
      "Epoch [606/1000], Loss: 7694499.7812\n",
      "Epoch [607/1000], Loss: 7660556.2812\n",
      "Epoch [608/1000], Loss: 7620164.6562\n",
      "Epoch [609/1000], Loss: 7590994.1562\n",
      "Epoch [610/1000], Loss: 7555591.5312\n",
      "Epoch [611/1000], Loss: 7522799.2500\n",
      "Epoch [612/1000], Loss: 7489929.6250\n",
      "Epoch [613/1000], Loss: 7450174.3438\n",
      "Epoch [614/1000], Loss: 7419854.3125\n",
      "Epoch [615/1000], Loss: 7395521.0938\n",
      "Epoch [616/1000], Loss: 7353394.9375\n",
      "Epoch [617/1000], Loss: 7315992.5625\n",
      "Epoch [618/1000], Loss: 7299344.3438\n",
      "Epoch [619/1000], Loss: 7273901.7812\n",
      "Epoch [620/1000], Loss: 7239649.7188\n",
      "Epoch [621/1000], Loss: 7205060.0938\n",
      "Epoch [622/1000], Loss: 7171382.5938\n",
      "Epoch [623/1000], Loss: 7144203.0000\n",
      "Epoch [624/1000], Loss: 7113321.0000\n",
      "Epoch [625/1000], Loss: 7089471.5625\n",
      "Epoch [626/1000], Loss: 7059466.6562\n",
      "Epoch [627/1000], Loss: 7022203.7812\n",
      "Epoch [628/1000], Loss: 7001440.5312\n",
      "Epoch [629/1000], Loss: 6977697.5625\n",
      "Epoch [630/1000], Loss: 6944192.6250\n",
      "Epoch [631/1000], Loss: 6921293.9375\n",
      "Epoch [632/1000], Loss: 6880438.4375\n",
      "Epoch [633/1000], Loss: 6867512.9375\n",
      "Epoch [634/1000], Loss: 6838818.6562\n",
      "Epoch [635/1000], Loss: 6806752.0000\n",
      "Epoch [636/1000], Loss: 6780706.3750\n",
      "Epoch [637/1000], Loss: 6755191.0938\n",
      "Epoch [638/1000], Loss: 6724670.2500\n",
      "Epoch [639/1000], Loss: 6703143.2188\n",
      "Epoch [640/1000], Loss: 6683543.2812\n",
      "Epoch [641/1000], Loss: 6657749.6250\n",
      "Epoch [642/1000], Loss: 6631563.7500\n",
      "Epoch [643/1000], Loss: 6602027.3750\n",
      "Epoch [644/1000], Loss: 6576212.1875\n",
      "Epoch [645/1000], Loss: 6557289.6875\n",
      "Epoch [646/1000], Loss: 6532129.0625\n",
      "Epoch [647/1000], Loss: 6507992.5000\n",
      "Epoch [648/1000], Loss: 6484970.5312\n",
      "Epoch [649/1000], Loss: 6466120.6562\n",
      "Epoch [650/1000], Loss: 6439783.4062\n",
      "Epoch [651/1000], Loss: 6415667.7188\n",
      "Epoch [652/1000], Loss: 6399803.5625\n",
      "Epoch [653/1000], Loss: 6375415.4688\n",
      "Epoch [654/1000], Loss: 6351105.0312\n",
      "Epoch [655/1000], Loss: 6333898.9062\n",
      "Epoch [656/1000], Loss: 6310058.8750\n",
      "Epoch [657/1000], Loss: 6286127.3125\n",
      "Epoch [658/1000], Loss: 6264406.7500\n",
      "Epoch [659/1000], Loss: 6250709.8125\n",
      "Epoch [660/1000], Loss: 6225303.4688\n",
      "Epoch [661/1000], Loss: 6207370.1562\n",
      "Epoch [662/1000], Loss: 6181063.0312\n",
      "Epoch [663/1000], Loss: 6161324.7188\n",
      "Epoch [664/1000], Loss: 6142123.9688\n",
      "Epoch [665/1000], Loss: 6120436.2812\n",
      "Epoch [666/1000], Loss: 6100661.1875\n",
      "Epoch [667/1000], Loss: 6088771.4062\n",
      "Epoch [668/1000], Loss: 6066913.4375\n",
      "Epoch [669/1000], Loss: 6049786.4688\n",
      "Epoch [670/1000], Loss: 6025522.5625\n",
      "Epoch [671/1000], Loss: 6011271.5312\n",
      "Epoch [672/1000], Loss: 5986926.2812\n",
      "Epoch [673/1000], Loss: 5969314.8438\n",
      "Epoch [674/1000], Loss: 5957006.2812\n",
      "Epoch [675/1000], Loss: 5940633.3750\n",
      "Epoch [676/1000], Loss: 5919396.2812\n",
      "Epoch [677/1000], Loss: 5904901.2812\n",
      "Epoch [678/1000], Loss: 5885448.8438\n",
      "Epoch [679/1000], Loss: 5867094.0312\n",
      "Epoch [680/1000], Loss: 5854739.7500\n",
      "Epoch [681/1000], Loss: 5834014.6875\n",
      "Epoch [682/1000], Loss: 5819469.5000\n",
      "Epoch [683/1000], Loss: 5806937.6562\n",
      "Epoch [684/1000], Loss: 5788444.4688\n",
      "Epoch [685/1000], Loss: 5766999.4062\n",
      "Epoch [686/1000], Loss: 5753561.1250\n",
      "Epoch [687/1000], Loss: 5739290.8438\n",
      "Epoch [688/1000], Loss: 5721896.6875\n",
      "Epoch [689/1000], Loss: 5704219.0938\n",
      "Epoch [690/1000], Loss: 5696234.5625\n",
      "Epoch [691/1000], Loss: 5675751.2500\n",
      "Epoch [692/1000], Loss: 5666144.3438\n",
      "Epoch [693/1000], Loss: 5648089.3125\n",
      "Epoch [694/1000], Loss: 5631185.7500\n",
      "Epoch [695/1000], Loss: 5620606.1250\n",
      "Epoch [696/1000], Loss: 5602325.7500\n",
      "Epoch [697/1000], Loss: 5594255.6875\n",
      "Epoch [698/1000], Loss: 5575708.0000\n",
      "Epoch [699/1000], Loss: 5560937.4062\n",
      "Epoch [700/1000], Loss: 5546846.8125\n",
      "Epoch [701/1000], Loss: 5531130.3125\n",
      "Epoch [702/1000], Loss: 5525249.2500\n",
      "Epoch [703/1000], Loss: 5505512.7812\n",
      "Epoch [704/1000], Loss: 5494129.2812\n",
      "Epoch [705/1000], Loss: 5485450.3750\n",
      "Epoch [706/1000], Loss: 5470520.6875\n",
      "Epoch [707/1000], Loss: 5460274.0625\n",
      "Epoch [708/1000], Loss: 5444796.7500\n",
      "Epoch [709/1000], Loss: 5436642.4375\n",
      "Epoch [710/1000], Loss: 5419324.7500\n",
      "Epoch [711/1000], Loss: 5409204.2188\n",
      "Epoch [712/1000], Loss: 5396586.2812\n",
      "Epoch [713/1000], Loss: 5385274.0312\n",
      "Epoch [714/1000], Loss: 5371147.5938\n",
      "Epoch [715/1000], Loss: 5363119.9688\n",
      "Epoch [716/1000], Loss: 5348924.3750\n",
      "Epoch [717/1000], Loss: 5335632.2500\n",
      "Epoch [718/1000], Loss: 5326386.4688\n",
      "Epoch [719/1000], Loss: 5314273.5000\n",
      "Epoch [720/1000], Loss: 5304546.0000\n",
      "Epoch [721/1000], Loss: 5290068.5000\n",
      "Epoch [722/1000], Loss: 5283849.0625\n",
      "Epoch [723/1000], Loss: 5271508.7188\n",
      "Epoch [724/1000], Loss: 5258837.0625\n",
      "Epoch [725/1000], Loss: 5247753.7812\n",
      "Epoch [726/1000], Loss: 5238286.7500\n",
      "Epoch [727/1000], Loss: 5229175.0312\n",
      "Epoch [728/1000], Loss: 5217005.1250\n",
      "Epoch [729/1000], Loss: 5210358.3438\n",
      "Epoch [730/1000], Loss: 5198825.8125\n",
      "Epoch [731/1000], Loss: 5186960.0312\n",
      "Epoch [732/1000], Loss: 5177038.9375\n",
      "Epoch [733/1000], Loss: 5168389.9688\n",
      "Epoch [734/1000], Loss: 5160286.0625\n",
      "Epoch [735/1000], Loss: 5150182.0312\n",
      "Epoch [736/1000], Loss: 5141150.6562\n",
      "Epoch [737/1000], Loss: 5132429.0938\n",
      "Epoch [738/1000], Loss: 5120895.0625\n",
      "Epoch [739/1000], Loss: 5113496.7500\n",
      "Epoch [740/1000], Loss: 5101372.0312\n",
      "Epoch [741/1000], Loss: 5095603.7500\n",
      "Epoch [742/1000], Loss: 5087441.7812\n",
      "Epoch [743/1000], Loss: 5075442.9375\n",
      "Epoch [744/1000], Loss: 5070203.9688\n",
      "Epoch [745/1000], Loss: 5058543.6250\n",
      "Epoch [746/1000], Loss: 5054860.4688\n",
      "Epoch [747/1000], Loss: 5040979.8438\n",
      "Epoch [748/1000], Loss: 5035834.0000\n",
      "Epoch [749/1000], Loss: 5028502.1875\n",
      "Epoch [750/1000], Loss: 5019022.1250\n",
      "Epoch [751/1000], Loss: 5014967.2500\n",
      "Epoch [752/1000], Loss: 5002154.6250\n",
      "Epoch [753/1000], Loss: 4999854.2812\n",
      "Epoch [754/1000], Loss: 4989557.3750\n",
      "Epoch [755/1000], Loss: 4979085.9375\n",
      "Epoch [756/1000], Loss: 4979612.4688\n",
      "Epoch [757/1000], Loss: 4965762.5000\n",
      "Epoch [758/1000], Loss: 4958023.9375\n",
      "Epoch [759/1000], Loss: 4951605.8438\n",
      "Epoch [760/1000], Loss: 4946056.7500\n",
      "Epoch [761/1000], Loss: 4935927.6562\n",
      "Epoch [762/1000], Loss: 4930416.9688\n",
      "Epoch [763/1000], Loss: 4923949.4375\n",
      "Epoch [764/1000], Loss: 4917108.7812\n",
      "Epoch [765/1000], Loss: 4908185.3750\n",
      "Epoch [766/1000], Loss: 4902369.0000\n",
      "Epoch [767/1000], Loss: 4896365.2188\n",
      "Epoch [768/1000], Loss: 4892507.3125\n",
      "Epoch [769/1000], Loss: 4883126.2188\n",
      "Epoch [770/1000], Loss: 4877851.5938\n",
      "Epoch [771/1000], Loss: 4870412.1562\n",
      "Epoch [772/1000], Loss: 4864107.3125\n",
      "Epoch [773/1000], Loss: 4858993.3125\n",
      "Epoch [774/1000], Loss: 4852595.5938\n",
      "Epoch [775/1000], Loss: 4845107.4375\n",
      "Epoch [776/1000], Loss: 4840311.7500\n",
      "Epoch [777/1000], Loss: 4833234.7500\n",
      "Epoch [778/1000], Loss: 4828106.2188\n",
      "Epoch [779/1000], Loss: 4821225.4062\n",
      "Epoch [780/1000], Loss: 4813877.7500\n",
      "Epoch [781/1000], Loss: 4810325.2812\n",
      "Epoch [782/1000], Loss: 4807779.8750\n",
      "Epoch [783/1000], Loss: 4804287.3750\n",
      "Epoch [784/1000], Loss: 4793750.4375\n",
      "Epoch [785/1000], Loss: 4789073.0625\n",
      "Epoch [786/1000], Loss: 4781492.7188\n",
      "Epoch [787/1000], Loss: 4776386.2188\n",
      "Epoch [788/1000], Loss: 4770668.8438\n",
      "Epoch [789/1000], Loss: 4769507.9375\n",
      "Epoch [790/1000], Loss: 4764420.5938\n",
      "Epoch [791/1000], Loss: 4759467.9062\n",
      "Epoch [792/1000], Loss: 4748689.3125\n",
      "Epoch [793/1000], Loss: 4745132.0625\n",
      "Epoch [794/1000], Loss: 4742407.2500\n",
      "Epoch [795/1000], Loss: 4736751.1250\n",
      "Epoch [796/1000], Loss: 4732342.3125\n",
      "Epoch [797/1000], Loss: 4725253.2500\n",
      "Epoch [798/1000], Loss: 4721784.0312\n",
      "Epoch [799/1000], Loss: 4718806.8438\n",
      "Epoch [800/1000], Loss: 4713682.7500\n",
      "Epoch [801/1000], Loss: 4707764.4375\n",
      "Epoch [802/1000], Loss: 4704525.9062\n",
      "Epoch [803/1000], Loss: 4700712.0312\n",
      "Epoch [804/1000], Loss: 4694773.5625\n",
      "Epoch [805/1000], Loss: 4690209.1562\n",
      "Epoch [806/1000], Loss: 4687319.2812\n",
      "Epoch [807/1000], Loss: 4682794.4375\n",
      "Epoch [808/1000], Loss: 4681317.7812\n",
      "Epoch [809/1000], Loss: 4674098.1875\n",
      "Epoch [810/1000], Loss: 4670590.8125\n",
      "Epoch [811/1000], Loss: 4665147.2812\n",
      "Epoch [812/1000], Loss: 4661756.2500\n",
      "Epoch [813/1000], Loss: 4658034.9375\n",
      "Epoch [814/1000], Loss: 4655882.9688\n",
      "Epoch [815/1000], Loss: 4650284.1875\n",
      "Epoch [816/1000], Loss: 4645372.0312\n",
      "Epoch [817/1000], Loss: 4644543.0312\n",
      "Epoch [818/1000], Loss: 4637217.6875\n",
      "Epoch [819/1000], Loss: 4634073.0312\n",
      "Epoch [820/1000], Loss: 4631218.3125\n",
      "Epoch [821/1000], Loss: 4628504.3438\n",
      "Epoch [822/1000], Loss: 4624190.5938\n",
      "Epoch [823/1000], Loss: 4622005.5938\n",
      "Epoch [824/1000], Loss: 4615494.5938\n",
      "Epoch [825/1000], Loss: 4613001.6875\n",
      "Epoch [826/1000], Loss: 4611407.8438\n",
      "Epoch [827/1000], Loss: 4606996.6250\n",
      "Epoch [828/1000], Loss: 4604145.8125\n",
      "Epoch [829/1000], Loss: 4601031.4688\n",
      "Epoch [830/1000], Loss: 4597808.8125\n",
      "Epoch [831/1000], Loss: 4594594.2500\n",
      "Epoch [832/1000], Loss: 4589569.2188\n",
      "Epoch [833/1000], Loss: 4586092.5000\n",
      "Epoch [834/1000], Loss: 4583436.5625\n",
      "Epoch [835/1000], Loss: 4584528.5312\n",
      "Epoch [836/1000], Loss: 4576775.2500\n",
      "Epoch [837/1000], Loss: 4575282.3125\n",
      "Epoch [838/1000], Loss: 4572477.5625\n",
      "Epoch [839/1000], Loss: 4571119.0938\n",
      "Epoch [840/1000], Loss: 4567327.9688\n",
      "Epoch [841/1000], Loss: 4564752.7812\n",
      "Epoch [842/1000], Loss: 4561476.8750\n",
      "Epoch [843/1000], Loss: 4558060.8438\n",
      "Epoch [844/1000], Loss: 4557483.3125\n",
      "Epoch [845/1000], Loss: 4553332.6875\n",
      "Epoch [846/1000], Loss: 4550008.0938\n",
      "Epoch [847/1000], Loss: 4546961.8438\n",
      "Epoch [848/1000], Loss: 4545045.1875\n",
      "Epoch [849/1000], Loss: 4541785.1250\n",
      "Epoch [850/1000], Loss: 4540631.1250\n",
      "Epoch [851/1000], Loss: 4538294.0000\n",
      "Epoch [852/1000], Loss: 4534079.9688\n",
      "Epoch [853/1000], Loss: 4532035.2812\n",
      "Epoch [854/1000], Loss: 4528051.5000\n",
      "Epoch [855/1000], Loss: 4525787.3125\n",
      "Epoch [856/1000], Loss: 4526228.5000\n",
      "Epoch [857/1000], Loss: 4521727.8750\n",
      "Epoch [858/1000], Loss: 4519410.9844\n",
      "Epoch [859/1000], Loss: 4517013.4688\n",
      "Epoch [860/1000], Loss: 4516371.9688\n",
      "Epoch [861/1000], Loss: 4516744.8438\n",
      "Epoch [862/1000], Loss: 4512184.0312\n",
      "Epoch [863/1000], Loss: 4508029.5938\n",
      "Epoch [864/1000], Loss: 4505817.2969\n",
      "Epoch [865/1000], Loss: 4504103.3750\n",
      "Epoch [866/1000], Loss: 4502493.8438\n",
      "Epoch [867/1000], Loss: 4500908.0469\n",
      "Epoch [868/1000], Loss: 4498304.8750\n",
      "Epoch [869/1000], Loss: 4498245.7656\n",
      "Epoch [870/1000], Loss: 4493923.1094\n",
      "Epoch [871/1000], Loss: 4491014.3594\n",
      "Epoch [872/1000], Loss: 4488423.3125\n",
      "Epoch [873/1000], Loss: 4487456.3750\n",
      "Epoch [874/1000], Loss: 4489240.6094\n",
      "Epoch [875/1000], Loss: 4482592.6250\n",
      "Epoch [876/1000], Loss: 4483069.4375\n",
      "Epoch [877/1000], Loss: 4481845.0781\n",
      "Epoch [878/1000], Loss: 4480760.9219\n",
      "Epoch [879/1000], Loss: 4475657.4844\n",
      "Epoch [880/1000], Loss: 4476175.0156\n",
      "Epoch [881/1000], Loss: 4475061.7500\n",
      "Epoch [882/1000], Loss: 4473635.0000\n",
      "Epoch [883/1000], Loss: 4470080.9062\n",
      "Epoch [884/1000], Loss: 4470048.6719\n",
      "Epoch [885/1000], Loss: 4467784.0156\n",
      "Epoch [886/1000], Loss: 4465600.0781\n",
      "Epoch [887/1000], Loss: 4465247.7812\n",
      "Epoch [888/1000], Loss: 4463086.2656\n",
      "Epoch [889/1000], Loss: 4460092.5312\n",
      "Epoch [890/1000], Loss: 4458679.5938\n",
      "Epoch [891/1000], Loss: 4457165.5781\n",
      "Epoch [892/1000], Loss: 4456591.4688\n",
      "Epoch [893/1000], Loss: 4455015.7344\n",
      "Epoch [894/1000], Loss: 4453253.6719\n",
      "Epoch [895/1000], Loss: 4452463.9844\n",
      "Epoch [896/1000], Loss: 4450274.1719\n",
      "Epoch [897/1000], Loss: 4448101.7500\n",
      "Epoch [898/1000], Loss: 4447257.8594\n",
      "Epoch [899/1000], Loss: 4445330.0312\n",
      "Epoch [900/1000], Loss: 4444431.8281\n",
      "Epoch [901/1000], Loss: 4442126.5469\n",
      "Epoch [902/1000], Loss: 4441041.6406\n",
      "Epoch [903/1000], Loss: 4440228.2500\n",
      "Epoch [904/1000], Loss: 4439456.7969\n",
      "Epoch [905/1000], Loss: 4437147.7969\n",
      "Epoch [906/1000], Loss: 4436845.9375\n",
      "Epoch [907/1000], Loss: 4435564.5469\n",
      "Epoch [908/1000], Loss: 4433768.1719\n",
      "Epoch [909/1000], Loss: 4432689.2500\n",
      "Epoch [910/1000], Loss: 4431222.8906\n",
      "Epoch [911/1000], Loss: 4430872.7188\n",
      "Epoch [912/1000], Loss: 4428664.8438\n",
      "Epoch [913/1000], Loss: 4428487.1562\n",
      "Epoch [914/1000], Loss: 4426611.2031\n",
      "Epoch [915/1000], Loss: 4425764.1719\n",
      "Epoch [916/1000], Loss: 4425172.6562\n",
      "Epoch [917/1000], Loss: 4423369.2344\n",
      "Epoch [918/1000], Loss: 4423057.9844\n",
      "Epoch [919/1000], Loss: 4421223.4688\n",
      "Epoch [920/1000], Loss: 4420766.8750\n",
      "Epoch [921/1000], Loss: 4419599.6719\n",
      "Epoch [922/1000], Loss: 4418963.1406\n",
      "Epoch [923/1000], Loss: 4417515.9531\n",
      "Epoch [924/1000], Loss: 4416291.2344\n",
      "Epoch [925/1000], Loss: 4415764.7812\n",
      "Epoch [926/1000], Loss: 4414639.6250\n",
      "Epoch [927/1000], Loss: 4414308.1250\n",
      "Epoch [928/1000], Loss: 4411124.5156\n",
      "Epoch [929/1000], Loss: 4412975.2188\n",
      "Epoch [930/1000], Loss: 4410519.4531\n",
      "Epoch [931/1000], Loss: 4410306.1094\n",
      "Epoch [932/1000], Loss: 4408640.4219\n",
      "Epoch [933/1000], Loss: 4407366.3125\n",
      "Epoch [934/1000], Loss: 4406357.7344\n",
      "Epoch [935/1000], Loss: 4406509.3750\n",
      "Epoch [936/1000], Loss: 4406287.8906\n",
      "Epoch [937/1000], Loss: 4405643.5156\n",
      "Epoch [938/1000], Loss: 4403711.1562\n",
      "Epoch [939/1000], Loss: 4402576.4688\n",
      "Epoch [940/1000], Loss: 4401918.6406\n",
      "Epoch [941/1000], Loss: 4400397.7188\n",
      "Epoch [942/1000], Loss: 4400004.7500\n",
      "Epoch [943/1000], Loss: 4399966.8906\n",
      "Epoch [944/1000], Loss: 4398460.8750\n",
      "Epoch [945/1000], Loss: 4398284.5312\n",
      "Epoch [946/1000], Loss: 4397755.2031\n",
      "Epoch [947/1000], Loss: 4396444.2969\n",
      "Epoch [948/1000], Loss: 4395486.9531\n",
      "Epoch [949/1000], Loss: 4395231.2344\n",
      "Epoch [950/1000], Loss: 4393958.7812\n",
      "Epoch [951/1000], Loss: 4393141.4375\n",
      "Epoch [952/1000], Loss: 4394599.2344\n",
      "Epoch [953/1000], Loss: 4393458.0781\n",
      "Epoch [954/1000], Loss: 4391813.9688\n",
      "Epoch [955/1000], Loss: 4390819.8125\n",
      "Epoch [956/1000], Loss: 4390776.5000\n",
      "Epoch [957/1000], Loss: 4390591.3281\n",
      "Epoch [958/1000], Loss: 4389581.4531\n",
      "Epoch [959/1000], Loss: 4388655.2031\n",
      "Epoch [960/1000], Loss: 4388079.9219\n",
      "Epoch [961/1000], Loss: 4386759.6250\n",
      "Epoch [962/1000], Loss: 4387002.4531\n",
      "Epoch [963/1000], Loss: 4386184.1250\n",
      "Epoch [964/1000], Loss: 4385139.2031\n",
      "Epoch [965/1000], Loss: 4385210.9531\n",
      "Epoch [966/1000], Loss: 4385529.0469\n",
      "Epoch [967/1000], Loss: 4384220.8750\n",
      "Epoch [968/1000], Loss: 4383242.6719\n",
      "Epoch [969/1000], Loss: 4382316.8125\n",
      "Epoch [970/1000], Loss: 4381791.7188\n",
      "Epoch [971/1000], Loss: 4381790.5000\n",
      "Epoch [972/1000], Loss: 4381770.6094\n",
      "Epoch [973/1000], Loss: 4380674.8750\n",
      "Epoch [974/1000], Loss: 4380353.3125\n",
      "Epoch [975/1000], Loss: 4380006.6250\n",
      "Epoch [976/1000], Loss: 4379341.5938\n",
      "Epoch [977/1000], Loss: 4378605.0625\n",
      "Epoch [978/1000], Loss: 4377888.5156\n",
      "Epoch [979/1000], Loss: 4377147.2344\n",
      "Epoch [980/1000], Loss: 4377530.7500\n",
      "Epoch [981/1000], Loss: 4377598.6094\n",
      "Epoch [982/1000], Loss: 4376777.1719\n",
      "Epoch [983/1000], Loss: 4376362.8281\n",
      "Epoch [984/1000], Loss: 4375045.7188\n",
      "Epoch [985/1000], Loss: 4376004.4844\n",
      "Epoch [986/1000], Loss: 4374678.4844\n",
      "Epoch [987/1000], Loss: 4373860.1094\n",
      "Epoch [988/1000], Loss: 4372924.4844\n",
      "Epoch [989/1000], Loss: 4373775.1719\n",
      "Epoch [990/1000], Loss: 4373198.4219\n",
      "Epoch [991/1000], Loss: 4372980.7344\n",
      "Epoch [992/1000], Loss: 4372337.0312\n",
      "Epoch [993/1000], Loss: 4371682.6719\n",
      "Epoch [994/1000], Loss: 4372067.0781\n",
      "Epoch [995/1000], Loss: 4371515.6250\n",
      "Epoch [996/1000], Loss: 4371217.6406\n",
      "Epoch [997/1000], Loss: 4370787.7188\n",
      "Epoch [998/1000], Loss: 4371054.6406\n",
      "Epoch [999/1000], Loss: 4369886.7188\n",
      "Epoch [1000/1000], Loss: 4368829.5000\n"
     ]
    }
   ],
   "source": [
    "VAD_best = VAD_beta(latent_dim=128, device=device)\n",
    "trainer_best = VAD_Trainer(var_decoder=VAD_best, dataloader=train_dl, latent_dim=128, beta=5e6, device=device, lr=0.001)\n",
    "_ = trainer_best.train(num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edda5b7e-e9d7-4b24-b253-566316440be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30594538897275925\n"
     ]
    }
   ],
   "source": [
    "num_test_samples = len(train_dl.dataset)\n",
    "opt = optim.Adam([trainer_best.latents], lr=1e-3)\n",
    "evaluate_loss = evaluate_model(model=VAD_best, test_dl=train_dl, opt=opt, latents=trainer_best.latents, epochs=1000, device=device)\n",
    "print(evaluate_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9360261-02b1-4d2c-96b3-c102c9c66b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "latents = VAD_best.reparameterize(trainer_best.latents)\n",
    "utils.plot_tsne(train_ds, latents, f\"tsne_beta_best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95bd661-ea43-4e60-93f0-cade1c016a2f",
   "metadata": {},
   "source": [
    "## Sample specific vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc2bfd32-1c89-4f4f-9494-9d7f6e7adc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = len(test_dl.dataset)\n",
    "mu_test = torch.randn(num_test_samples, VAD_best.latent_dim, device=device, requires_grad=True)\n",
    "sigma_test = torch.randn(num_test_samples, VAD_best.latent_dim, device=device, requires_grad=True)\n",
    "test_latents = torch.nn.parameter.Parameter(torch.stack([mu_test, sigma_test], dim=1)).to(device)\n",
    "opt = optim.Adam([test_latents], lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6568406b-c6c5-40af-9339-9825107b7bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AD has finished test evaluation with a test loss of 0.3141459207981825.\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluate_model(model=VAD_best, test_dl=test_dl, opt=opt, latents=test_latents, epochs=1000, device=device)\n",
    "print(f\"AD has finished test evaluation with a test loss of {test_loss}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a5d3b54-cf39-4e45-af3f-8a573b9b3007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_test_latents = VAD_best.reparameterize(test_latents)\n",
    "utils.plot_tsne(test_ds, final_test_latents, f\"tsne_test_beta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad556234-27db-4273-b409-cc4d0380268a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(49)\n",
    "sampled_indices = random.sample(range(1000), 5)\n",
    "random_latents_tensor = torch.randn(5,VAD_best.latent_dim, device=device)\n",
    "\n",
    "\n",
    "sampled_test_images = VAD_best(test_latents[sampled_indices]).view(-1, 1, 28, 28)\n",
    "random_test_images = VAD_best.decoder(random_latents_tensor).view(-1, 1, 28, 28)\n",
    "\n",
    "utils.save_images(sampled_test_images, \"sampled_test_images_VAD_beta.png\")\n",
    "utils.save_images(random_test_images, \"random_test_images_VAD_beta.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787e7d41-cb83-46b6-95b0-33a7258e5fee",
   "metadata": {},
   "source": [
    "## Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e96f6f8-17b2-40b8-8f4e-4b8998ad729a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sampled_indices = [1, 25]\n",
    "sampled_latents = [final_test_latents[i] for i in sampled_indices]\n",
    "weights = np.linspace(0, 1, 7)\n",
    "interpolated_latents = [w * sampled_latents[0] + (1 - w) * sampled_latents[1] for w in weights]\n",
    "interpolated_latents_tensor = torch.stack(interpolated_latents)\n",
    "interpolated_images = VAD_best.decoder(interpolated_latents_tensor).view(-1, 1, 28, 28)\n",
    "utils.save_images(interpolated_images, \"interpolated_images_VAD_beta.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
