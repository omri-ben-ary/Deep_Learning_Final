{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bb3860-f4ed-4dc2-bb65-fd5bab45d709",
   "metadata": {},
   "outputs": [],
   "source": [
    "from VariationalAutoDecoder import VariationalAutoDecoder as VAD\n",
    "from VAD_Trainer import VAD_Trainer\n",
    "import utils\n",
    "from evaluate import evaluate_model\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d227682-fe2c-4635-8f22-43695ac358ee",
   "metadata": {},
   "source": [
    "## Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb85c21c-5862-401b-88a4-e20796edf5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, train_dl, test_ds, test_dl = utils.create_dataloaders(data_path=\"dataset\" ,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c9b43a-4434-4820-92c0-caf522961bb1",
   "metadata": {},
   "source": [
    "## Train Auto Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb06f910-ca78-4244-9055-91cfcf343f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "architectures = [\n",
    "    {\n",
    "        \"mu_net\": nn.Sequential(\n",
    "            nn.Linear(128, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 128)\n",
    "        ),\n",
    "        \"log_var_net\": nn.Sequential(\n",
    "            nn.Linear(128, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 128)\n",
    "        )\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"mu_net\": nn.Sequential(\n",
    "            nn.Linear(128, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128)\n",
    "        ),\n",
    "        \"log_var_net\": nn.Sequential(\n",
    "            nn.Linear(128, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128)\n",
    "        )\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"mu_net\": nn.Sequential(\n",
    "            nn.Linear(128, 512),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128)\n",
    "        ),\n",
    "        \"log_var_net\": nn.Sequential(\n",
    "            nn.Linear(128, 512),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128)\n",
    "        )\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# latent_dims = [dim for dim in [64, 32, 128, 16, 10] for _ in range(5)]\n",
    "VADs = [VAD(mu_layers=arch['mu_net'], var_layers=arch['log_var_net'], device=device) for arch in architectures]# for _ in range(5)]\n",
    "# learning_rates = [lr for lr in [0.001, 0.0005, 0.0001, 0.002, 0.005] for _ in range(5)]\n",
    "trainers = [VAD_Trainer(var_decoder=VADs[i], dataloader=train_dl, latent_dim=128, device=device, lr=1e-2) for i in range(len(VADs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13baccde-a05f-4922-b4b9-681d7aecfc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the results list to hold all the data\n",
    "num_test_samples = len(test_dl.dataset)\n",
    "\n",
    "# Create latent parameters and optimizers for each trainer\n",
    "temp_latents = torch.randn(10, self.latent_dim).to(self.device)\n",
    "latents_list = [torch.nn.Parameter((torch.stack([temp_latents[label,:] for label in dataloader.dataset.y])).to(device) for i in range(len(VADs))]# for _ in range(5)]\n",
    "optimizers = [optim.Adam([latents], lr=1e-3) for latents in latents_list]\n",
    "\n",
    "# Save results to a CSV file\n",
    "csv_file_path = 'results_VAD_temp.csv'\n",
    "\n",
    "# Write header to the CSV file first\n",
    "with open(csv_file_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    header = ['Index'] + [f'Epoch {i+1} Loss' for i in range(500)] + ['Final Test Loss']\n",
    "    writer.writerow(header)\n",
    "\n",
    "# Main training and evaluation loop\n",
    "for index, trainer in enumerate(trainers):\n",
    "    start_time = time.time()  # Record the start time\n",
    "    train_loss = trainer.train(num_epochs=500)  # Train the model\n",
    "    end_time = time.time()  # Record the end time\n",
    "    \n",
    "    elapsed_time = end_time - start_time  # Calculate elapsed time\n",
    "    print(f\"Trainer {index} has finished training in {elapsed_time:.2f} seconds.\")\n",
    "\n",
    "    start_time = time.time()  # Record the start time\n",
    "    test_loss = evaluate_model(model=VADs[index], test_dl=test_dl, opt=optimizers[index], latents=latents_list[index], epochs=500, device=device) \n",
    "    end_time = time.time()  # Record the end time\n",
    "    \n",
    "    elapsed_time = end_time - start_time  # Calculate elapsed time\n",
    "    print(f\"AD {index} has finished test evaluation in {elapsed_time:.2f} seconds.\")\n",
    "\n",
    "    # Prepare the row to be saved\n",
    "    row = [index] + train_loss + [test_loss]\n",
    "\n",
    "    # Append results to the CSV file after each iteration\n",
    "    with open(csv_file_path, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"Results saved to {csv_file_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27147e64-6c63-4528-bc12-99750ba8ccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(trainers)):\n",
    "    utils.plot_tsne(train_ds, trainers[i].latents, f\"tsne_kl_{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64685dc-0a81-42d3-b67b-cf78d1e34e9e",
   "metadata": {},
   "source": [
    "## Fine Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0801bf72-57eb-4d39-9a97-0330af95e4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = {\n",
    "        \"mu_net\": nn.Sequential(\n",
    "            nn.Linear(128, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 128)\n",
    "        ),\n",
    "        \"log_var_net\": nn.Sequential(\n",
    "            nn.Linear(128, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 128)\n",
    "        )\n",
    "    }\n",
    "\n",
    "learning_rates = [0.001, 0.0001, 0.005]\n",
    "VADs_ft = [VAD(mu_layers=arch['mu_net'], var_layers=arch['log_var_net'], device=device) for _ in range(len(learning_rates))]# for _ in range(5)]\n",
    "trainers_ft = [VAD_Trainer(var_decoder=VADs_ft[i], dataloader=train_dl, latent_dim=128, device=device, lr=learning_rates[i]) for i in range(len(VADs_ft))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d52bc6-5d45-4c1b-8c4a-ec606d33ce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the results list to hold all the data\n",
    "num_test_samples = len(test_dl.dataset)\n",
    "\n",
    "# Create latent parameters and optimizers for each trainer\n",
    "latents_list_ft = [torch.nn.Parameter(torch.randn(num_test_samples, trainers_ft[i].latent_dim).to(device)) for i in range(len(VADs_ft))]# for _ in range(5)]\n",
    "optimizers = [optim.Adam([latents], lr=1e-3) for latents in latents_list_ft]\n",
    "\n",
    "# Save results to a CSV file\n",
    "csv_file_path = 'results_VAD_ft.csv'\n",
    "\n",
    "# Write header to the CSV file first\n",
    "with open(csv_file_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    header = ['Index'] + [f'Epoch {i+1} Loss' for i in range(500)] + ['Final Test Loss']\n",
    "    writer.writerow(header)\n",
    "\n",
    "# Main training and evaluation loop\n",
    "for index, trainer in enumerate(trainers_ft):\n",
    "    start_time = time.time()  # Record the start time\n",
    "    train_loss = trainer.train(num_epochs=500)  # Train the model\n",
    "    end_time = time.time()  # Record the end time\n",
    "    \n",
    "    elapsed_time = end_time - start_time  # Calculate elapsed time\n",
    "    print(f\"Trainer {index} has finished training in {elapsed_time:.2f} seconds.\")\n",
    "\n",
    "    start_time = time.time()  # Record the start time\n",
    "    test_loss = evaluate_model(model=VADs_ft[index], test_dl=test_dl, opt=optimizers[index], latents=latents_list_ft[index], epochs=500, device=device) \n",
    "    end_time = time.time()  # Record the end time\n",
    "    \n",
    "    elapsed_time = end_time - start_time  # Calculate elapsed time\n",
    "    print(f\"AD {index} has finished test evaluation in {elapsed_time:.2f} seconds.\")\n",
    "\n",
    "    # Prepare the row to be saved\n",
    "    row = [index] + train_loss + [test_loss]\n",
    "\n",
    "    # Append results to the CSV file after each iteration\n",
    "    with open(csv_file_path, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"Results saved to {csv_file_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08afa67a-6bc0-4802-8dfd-d3cf9350207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(trainers_ft)):\n",
    "    utils.plot_tsne(train_ds, trainers_ft[i].latents, f\"tsne_kl_ft_{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd033aaf-061c-4bd6-b32e-40466dd1027f",
   "metadata": {},
   "source": [
    "## Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc862a48-c47c-49ce-b233-71192301ee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = {\n",
    "        \"mu_net\": nn.Sequential(\n",
    "            nn.Linear(128, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 128)\n",
    "        ),\n",
    "        \"log_var_net\": nn.Sequential(\n",
    "            nn.Linear(128, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 128)\n",
    "        )\n",
    "    }\n",
    "\n",
    "VAD_best = VAD(mu_layers=arch['mu_net'], var_layers=arch['log_var_net'], device=device)\n",
    "trainer_best = VAD_Trainer(var_decoder=VAD_best, dataloader=train_dl, latent_dim=128, device=device, lr=0.001)\n",
    "trainer_best.train(num_epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95bd661-ea43-4e60-93f0-cade1c016a2f",
   "metadata": {},
   "source": [
    "## Sample specific vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2bfd32-1c89-4f4f-9494-9d7f6e7adc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = len(test_dl.dataset)\n",
    "latents = torch.nn.Parameter(torch.randn(num_test_samples, trainer.latent_dim).to(device))\n",
    "opt = optim.Adam([latents], lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6568406b-c6c5-40af-9339-9825107b7bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = evaluate_model(model=decoder, test_dl=test_dl, opt=opt, latents=latents, epochs=1000, device=device)\n",
    "print(f\"AD has finished test evaluation with a test loss of {test_loss}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad556234-27db-4273-b409-cc4d0380268a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sample 5 indices from the test dataset\n",
    "random.seed(6)\n",
    "sampled_indices = random.sample(range(len(latents)), 5)\n",
    "\n",
    "# Extract the corresponding vectors (input data) and their labels\n",
    "sampled_latents = [latents[i] for i in sampled_indices]  # Only selecting input data, not labels\n",
    "\n",
    "# Convert to a single tensor (optional)\n",
    "sampled_latents_tensor = torch.stack(sampled_latents)\n",
    "random_latents_tensor = torch.randn_like(sampled_latents_tensor)\n",
    "\n",
    "print(\"Sampled Vectors Shape:\", sampled_latents_tensor.shape)  # Should be (5, *) depending on your data shape\n",
    "print(\"Random Vectors Shape:\", random_latents_tensor.shape)  # Should be (5, *) depending on your data shape\n",
    "\n",
    "sampled_test_images = decoder(sampled_latents_tensor).view(-1, 1, 28, 28)\n",
    "random_test_images = decoder(random_latents_tensor).view(-1, 1, 28, 28)\n",
    "\n",
    "print(\"Sampled Images Shape:\", sampled_test_images.shape)  # Should be (5, *) depending on your data shape\n",
    "utils.save_images(sampled_test_images, \"sampled_test_images.png\")\n",
    "utils.save_images(random_test_images, \"random_test_images.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
