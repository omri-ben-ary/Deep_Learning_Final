{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04bb3860-f4ed-4dc2-bb65-fd5bab45d709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from VariationalAutoDecoder import VariationalAutoDecoder as VAD\n",
    "from VAD_Trainer import VAD_Trainer\n",
    "import utils\n",
    "from evaluate import evaluate_model\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d227682-fe2c-4635-8f22-43695ac358ee",
   "metadata": {},
   "source": [
    "## Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb85c21c-5862-401b-88a4-e20796edf5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, train_dl, test_ds, test_dl = utils.create_dataloaders(data_path=\"dataset\" ,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c9b43a-4434-4820-92c0-caf522961bb1",
   "metadata": {},
   "source": [
    "## Train Auto Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb06f910-ca78-4244-9055-91cfcf343f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dims = [16, 32, 64, 128]\n",
    "betas = [1e5, 5e5, 1e6, 5e6]\n",
    "VADs = [VAD(latent_dim=dim, device=device) for (dim,_) in list(itertools.product(latent_dims, betas))]\n",
    "trainers = [VAD_Trainer(var_decoder=VADs[i], dataloader=train_dl, latent_dim=dim, beta=beta, device=device, lr=1e-3)\n",
    "            for i,(dim,beta) in enumerate(list(itertools.product(latent_dims, betas)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13baccde-a05f-4922-b4b9-681d7aecfc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the results list to hold all the data\n",
    "num_test_samples = len(train_dl.dataset)\n",
    "\n",
    "# latents_list = [torch.nn.Parameter(torch.stack([temp_latents[label,:] for label in train_dl.dataset.y])).to(device) for i in range(len(VADs))]\n",
    "# optimizers = [optim.Adam([latents], lr=1e-3) for latents in latents_list]\n",
    "\n",
    "# Save results to a CSV file\n",
    "csv_file_path = 'results_VAD_omri.csv'\n",
    "\n",
    "# Write header to the CSV file first\n",
    "with open(csv_file_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    header = ['Index'] + [f'Epoch {i+1} Loss' for i in range(500)] + ['Final Train Loss']\n",
    "    writer.writerow(header)\n",
    "\n",
    "# Main training and evaluation loop\n",
    "for index, trainer in enumerate(trainers):\n",
    "    # mu = torch.randn(len(train_dl.dataset), trainer.latent_dim, device=device, requires_grad=True)\n",
    "    # sigma = torch.randn(len(train_dl.dataset), trainer.latent_dim, device=device, requires_grad=True)\n",
    "    # latents = torch.nn.parameter.Parameter(torch.stack([mu, sigma], dim=1)).to(device)\n",
    "    optimizer = optim.Adam([trainer.latents], lr=1e-3)\n",
    "    \n",
    "    start_time = time.time()  # Record the start time\n",
    "    train_loss = trainer.train(num_epochs=500)  # Train the model\n",
    "    end_time = time.time()  # Record the end time\n",
    "    \n",
    "    elapsed_time = end_time - start_time  # Calculate elapsed time\n",
    "    print(f\"Trainer {index} has finished training in {elapsed_time:.2f} seconds.\")\n",
    "\n",
    "    start_time = time.time()  # Record the start time\n",
    "    test_loss = evaluate_model(model=VADs[index], test_dl=train_dl, opt=optimizer, latents=trainer.latents, epochs=500, device=device) \n",
    "    end_time = time.time()  # Record the end time\n",
    "    \n",
    "    elapsed_time = end_time - start_time  # Calculate elapsed time\n",
    "    print(f\"AD {index} has finished train evaluation in {elapsed_time:.2f} seconds.\")\n",
    "\n",
    "    # Prepare the row to be saved\n",
    "    row = [index] + train_loss + [test_loss]\n",
    "\n",
    "    # Append results to the CSV file after each iteration\n",
    "    with open(csv_file_path, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"Results saved to {csv_file_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27147e64-6c63-4528-bc12-99750ba8ccae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(trainers)):\n",
    "    latents = VADs[i].reparameterize(trainers[i].latents)\n",
    "    utils.plot_tsne(train_ds, latents, f\"tsne_omri_{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08afa67a-6bc0-4802-8dfd-d3cf9350207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(trainers_ft)):\n",
    "    utils.plot_tsne(train_ds, trainers_ft[i].latents, f\"tsne_kl_ft_{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd033aaf-061c-4bd6-b32e-40466dd1027f",
   "metadata": {},
   "source": [
    "## Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc862a48-c47c-49ce-b233-71192301ee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAD_best = VAD(latent_dim=128, device=device)\n",
    "trainer_best = VAD_Trainer(var_decoder=VAD_best, dataloader=train_dl, latent_dim=128, beta=5e6, device=device, lr=0.001)\n",
    "_ = trainer_best.train(num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edda5b7e-e9d7-4b24-b253-566316440be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = len(train_dl.dataset)\n",
    "#latents_check = torch.nn.Parameter(torch.randn(num_test_samples, trainer_best.latent_dim).to(device))\n",
    "opt = optim.Adam([trainer_best.latents], lr=1e-3)\n",
    "evaluate_loss = evaluate_model(model=VAD_best, test_dl=train_dl, opt=opt, latents=trainer_best.latents, epochs=1000, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c973b4ed-ae7d-403f-8159-4c6feaa2c80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2757660485804081\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9360261-02b1-4d2c-96b3-c102c9c66b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# means = trainer_best.latents[:,0,:]\n",
    "# stds = trainer_best.latents[:,1,:]\n",
    "# print(stds.var())\n",
    "# print(means.var())\n",
    "# latents = torch.normal(means, stds.pow(2))\n",
    "latents = VAD_best.reparameterize(trainer_best.latents)\n",
    "# print(latents.shape)\n",
    "utils.plot_tsne(train_ds, latents, f\"tsne_omri_best?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95bd661-ea43-4e60-93f0-cade1c016a2f",
   "metadata": {},
   "source": [
    "## Sample specific vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc2bfd32-1c89-4f4f-9494-9d7f6e7adc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = len(test_dl.dataset)\n",
    "mu_test = torch.randn(num_test_samples, VAD_best.latent_dim, device=device, requires_grad=True)\n",
    "sigma_test = torch.randn(num_test_samples, VAD_best.latent_dim, device=device, requires_grad=True)\n",
    "test_latents = torch.nn.parameter.Parameter(torch.stack([mu_test, sigma_test], dim=1)).to(device)\n",
    "opt = optim.Adam([test_latents], lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6568406b-c6c5-40af-9339-9825107b7bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AD has finished test evaluation with a test loss of 0.272798553109169.\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluate_model(model=VAD_best, test_dl=test_dl, opt=opt, latents=test_latents, epochs=1000, device=device)\n",
    "print(f\"AD has finished test evaluation with a test loss of {test_loss}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a5d3b54-cf39-4e45-af3f-8a573b9b3007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_test_latents = VAD_best.reparameterize(test_latents)\n",
    "utils.plot_tsne(test_ds, final_test_latents, f\"tsne_test_omri\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad556234-27db-4273-b409-cc4d0380268a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sample 5 indices from the test dataset\n",
    "random.seed(6)\n",
    "sampled_indices = random.sample(range(1000), 5)\n",
    "\n",
    "# Extract the corresponding vectors (input data) and their labels\n",
    "#sampled_latents = [final_test_latents[i] for i in sampled_indices]\n",
    "\n",
    "# Convert to a single tensor (optional)\n",
    "# sampled_latents_tensor = torch.stack(sampled_latents)\n",
    "random_latents_tensor = 10000 * torch.randn_like(test_latents[sampled_indices])\n",
    "\n",
    "sampled_test_images = VAD_best(test_latents[sampled_indices]).view(-1, 1, 28, 28)\n",
    "random_test_images = VAD_best(random_latents_tensor).view(-1, 1, 28, 28)\n",
    "\n",
    "utils.save_images(sampled_test_images, \"sampled_test_images_VAD_Omri.png\")\n",
    "utils.save_images(random_test_images, \"random_test_images_VAD_Omri.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787e7d41-cb83-46b6-95b0-33a7258e5fee",
   "metadata": {},
   "source": [
    "## Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e96f6f8-17b2-40b8-8f4e-4b8998ad729a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "random.seed(44)\n",
    "sampled_indices = random.sample(range(len(latents_best)), 2)\n",
    "sampled_latents = [latents_best[i] for i in sampled_indices]\n",
    "weights = np.linspace(0, 1, 7)\n",
    "interpolated_latents = [w * sampled_latents[0] + (1 - w) * sampled_latents[1] for w in weights]\n",
    "interpolated_latents_tensor = torch.stack(interpolated_latents)\n",
    "interpolated_images = VAD_best(interpolated_latents_tensor).view(-1, 1, 28, 28)\n",
    "utils.save_images(interpolated_images, \"interpolated_images.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
