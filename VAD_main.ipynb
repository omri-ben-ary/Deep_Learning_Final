{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04bb3860-f4ed-4dc2-bb65-fd5bab45d709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from VariationalAutoDecoder import VariationalAutoDecoder as VAD\n",
    "from VAD_Trainer import VAD_Trainer\n",
    "import utils\n",
    "from evaluate import evaluate_model\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d227682-fe2c-4635-8f22-43695ac358ee",
   "metadata": {},
   "source": [
    "## Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb85c21c-5862-401b-88a4-e20796edf5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, train_dl, test_ds, test_dl = utils.create_dataloaders(data_path=\"dataset\" ,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c9b43a-4434-4820-92c0-caf522961bb1",
   "metadata": {},
   "source": [
    "## Train Auto Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb06f910-ca78-4244-9055-91cfcf343f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "architectures = [\n",
    "    # Architecture 1: Balanced Depth with Dropout\n",
    "    {\n",
    "        \"mu_net\": nn.Sequential(\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256)\n",
    "        ),\n",
    "        \"log_var_net\": nn.Sequential(\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256)\n",
    "        )\n",
    "    },\n",
    "\n",
    "    # Architecture 2: Deeper and Wider Network with Batch Normalization\n",
    "    {\n",
    "        \"mu_net\": nn.Sequential(\n",
    "            nn.Linear(256, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256)\n",
    "        ),\n",
    "        \"log_var_net\": nn.Sequential(\n",
    "            nn.Linear(256, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256)\n",
    "        )\n",
    "    },\n",
    "\n",
    "    # Architecture 3: Lightweight Architecture with High Dropout\n",
    "    {\n",
    "        \"mu_net\": nn.Sequential(\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 256)\n",
    "        ),\n",
    "        \"log_var_net\": nn.Sequential(\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 256)\n",
    "        )\n",
    "    },\n",
    "\n",
    "    # Architecture 4: Residual Connections and Dropout\n",
    "    {\n",
    "        \"mu_net\": nn.Sequential(\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Sequential(\n",
    "                nn.Linear(512, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.25)\n",
    "            ),\n",
    "            nn.Linear(512, 256)\n",
    "        ),\n",
    "        \"log_var_net\": nn.Sequential(\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Sequential(\n",
    "                nn.Linear(512, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.25)\n",
    "            ),\n",
    "            nn.Linear(512, 256)\n",
    "        )\n",
    "    },\n",
    "\n",
    "    # Architecture 5: Small Network with Layer Normalization\n",
    "    {\n",
    "        \"mu_net\": nn.Sequential(\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256)\n",
    "        ),\n",
    "        \"log_var_net\": nn.Sequential(\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256)\n",
    "        )\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# latent_dims = [dim for dim in [64, 32, 128, 16, 10] for _ in range(5)]\n",
    "VADs = [VAD(mu_layers=arch['mu_net'], var_layers=arch['log_var_net']) for arch in architectures]# for _ in range(5)]\n",
    "# learning_rates = [lr for lr in [0.001, 0.0005, 0.0001, 0.002, 0.005] for _ in range(5)]\n",
    "trainers = [VAD_Trainer(var_decoder=VADs[i], dataloader=train_dl, latent_dim=256, device=device, lr=1e-3) for i in range(len(VADs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13baccde-a05f-4922-b4b9-681d7aecfc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 16, 16])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 1, 28, 28]' is invalid for input of size 4194304",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, trainer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trainers):\n\u001b[1;32m     19\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()  \u001b[38;5;66;03m# Record the start time\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()  \u001b[38;5;66;03m# Record the end time\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     elapsed_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time  \u001b[38;5;66;03m# Calculate elapsed time\u001b[39;00m\n",
      "File \u001b[0;32m~/Deep_Learning_Final/Deep_Learning_Final/VAD_Trainer.py:78\u001b[0m, in \u001b[0;36mVAD_Trainer.train\u001b[0;34m(self, num_epochs, early_stopping)\u001b[0m\n\u001b[1;32m     76\u001b[0m best_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 78\u001b[0m     epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(epoch_loss)\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Deep_Learning_Final/Deep_Learning_Final/VAD_Trainer.py:56\u001b[0m, in \u001b[0;36mVAD_Trainer.train_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatents[batch_idx \u001b[38;5;241m*\u001b[39m batch_size : (batch_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m batch_size, :]\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m#print(z.sum())\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m reconstructed_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_decoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(images, reconstructed_images, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_decoder\u001b[38;5;241m.\u001b[39mmu, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_decoder\u001b[38;5;241m.\u001b[39mlog_var)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniconda3/envs/AD-Project/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/AD-Project/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Deep_Learning_Final/Deep_Learning_Final/VariationalAutoDecoder.py:61\u001b[0m, in \u001b[0;36mVariationalAutoDecoder.forward\u001b[0;34m(self, latent_vec)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(z\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     60\u001b[0m rec_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(z)\n\u001b[0;32m---> 61\u001b[0m rec_image \u001b[38;5;241m=\u001b[39m \u001b[43mrec_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rec_image\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 1, 28, 28]' is invalid for input of size 4194304"
     ]
    }
   ],
   "source": [
    "# Initialize the results list to hold all the data\n",
    "num_test_samples = len(test_dl.dataset)\n",
    "\n",
    "# Create latent parameters and optimizers for each trainer\n",
    "latents_list = [torch.nn.Parameter(torch.randn(num_test_samples, trainers[i].latent_dim).to(device)) for i in range(5)]# for _ in range(5)]\n",
    "optimizers = [optim.Adam([latents], lr=1e-3) for latents in latents_list]\n",
    "\n",
    "# Save results to a CSV file\n",
    "csv_file_path = 'results_VAD_temp.csv'\n",
    "\n",
    "# Write header to the CSV file first\n",
    "with open(csv_file_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    header = ['Index'] + [f'Epoch {i+1} Loss' for i in range(200)] + ['Final Test Loss']\n",
    "    writer.writerow(header)\n",
    "\n",
    "# Main training and evaluation loop\n",
    "for index, trainer in enumerate(trainers):\n",
    "    start_time = time.time()  # Record the start time\n",
    "    train_loss = trainer.train(num_epochs=200)  # Train the model\n",
    "    end_time = time.time()  # Record the end time\n",
    "    \n",
    "    elapsed_time = end_time - start_time  # Calculate elapsed time\n",
    "    print(f\"Trainer {index} has finished training in {elapsed_time:.2f} seconds.\")\n",
    "\n",
    "    start_time = time.time()  # Record the start time\n",
    "    test_loss = evaluate_model(model=VADs[index], test_dl=test_dl, opt=optimizers[index], latents=latents_list[index], epochs=100, device=device) \n",
    "    end_time = time.time()  # Record the end time\n",
    "    \n",
    "    elapsed_time = end_time - start_time  # Calculate elapsed time\n",
    "    print(f\"AD {index} has finished test evaluation in {elapsed_time:.2f} seconds.\")\n",
    "\n",
    "    # Prepare the row to be saved\n",
    "    row = [index] + train_loss + [test_loss]\n",
    "\n",
    "    # Append results to the CSV file after each iteration\n",
    "    with open(csv_file_path, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"Results saved to {csv_file_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a27695b-9668-45db-a6d8-193deb9cc1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu is tensor([[-0.0075,  0.3937,  0.4571,  ..., -0.4561,  1.1955,  0.5147],\n",
      "        [ 0.9493,  0.4686, -0.2689,  ..., -0.5194, -0.0215, -0.4969],\n",
      "        [ 0.5074,  0.0087,  0.3487,  ..., -0.1180, -0.4948, -0.1248],\n",
      "        ...,\n",
      "        [ 0.2776, -0.6547, -0.8342,  ..., -0.4688, -0.1061,  0.5185],\n",
      "        [ 0.4887,  0.7447,  0.2863,  ..., -0.8428,  1.5053, -0.2989],\n",
      "        [ 0.6870,  0.3778, -0.3577,  ...,  0.1559, -0.9798,  0.2507]],\n",
      "       device='cuda:0')  \n",
      "var is tensor([[ 1.8487,  0.9140,  1.2749,  ...,  1.9546,  2.4533,  1.5519],\n",
      "        [ 2.4893,  0.6447,  3.2543,  ...,  3.9568,  2.7078,  0.4194],\n",
      "        [ 2.2148,  1.8637,  3.0983,  ...,  1.6641,  2.5564,  1.1311],\n",
      "        ...,\n",
      "        [ 1.3752,  1.4912,  1.1600,  ..., -0.6805,  1.9990,  1.8013],\n",
      "        [ 1.8618,  2.3971,  3.3418,  ...,  1.4460,  1.9874,  1.3415],\n",
      "        [ 0.1172,  1.9712,  1.6490,  ...,  0.8563,  2.3387,  1.7930]],\n",
      "       device='cuda:0')  \n"
     ]
    }
   ],
   "source": [
    "print(f\"mu is {VADs[0].mu}  \")\n",
    "print(f\"var is {VADs[0].log_var}  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27147e64-6c63-4528-bc12-99750ba8ccae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils.plot_tsne(train_ds, trainers[0].latents, \"tsne0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95bd661-ea43-4e60-93f0-cade1c016a2f",
   "metadata": {},
   "source": [
    "## Sample specific vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bebb7ef-611d-40c0-a8d6-159c778b684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = nn.Sequential(\n",
    "        nn.Linear(256, 512),\n",
    "        nn.BatchNorm1d(512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.25),\n",
    "        nn.Linear(512, 1024),\n",
    "        nn.BatchNorm1d(1024),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(1024, 2048),\n",
    "        nn.BatchNorm1d(2048),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(2048, 4096),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(4096, 784)\n",
    "    )\n",
    "decoder = AutoDecoder.AutoDecoder(arch)\n",
    "trainer = AD_Trainer.AD_Trainer(decoder=decoder, dataloader=train_dl, latent_dim=256, device=device, lr=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc2bfd32-1c89-4f4f-9494-9d7f6e7adc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: 0.0718\n",
      "Epoch [2/200], Loss: 0.0713\n",
      "Epoch [3/200], Loss: 0.0686\n",
      "Epoch [4/200], Loss: 0.0682\n",
      "Epoch [5/200], Loss: 0.0726\n",
      "Epoch [6/200], Loss: 0.0740\n",
      "Epoch [7/200], Loss: 0.0714\n",
      "Epoch [8/200], Loss: 0.0662\n",
      "Epoch [9/200], Loss: 0.0631\n",
      "Epoch [10/200], Loss: 0.0636\n",
      "Epoch [11/200], Loss: 0.0643\n",
      "Epoch [12/200], Loss: 0.0651\n",
      "Epoch [13/200], Loss: 0.0648\n",
      "Epoch [14/200], Loss: 0.0687\n",
      "Epoch [15/200], Loss: 0.0705\n",
      "Epoch [16/200], Loss: 0.0666\n",
      "Epoch [17/200], Loss: 0.0629\n",
      "Epoch [18/200], Loss: 0.0643\n",
      "Epoch [19/200], Loss: 0.0640\n",
      "Epoch [20/200], Loss: 0.0629\n",
      "Epoch [21/200], Loss: 0.0645\n",
      "Epoch [22/200], Loss: 0.0647\n",
      "Epoch [23/200], Loss: 0.0669\n",
      "Epoch [24/200], Loss: 0.0721\n",
      "Epoch [25/200], Loss: 0.0681\n",
      "Epoch [26/200], Loss: 0.0658\n",
      "Epoch [27/200], Loss: 0.0668\n",
      "Epoch [28/200], Loss: 0.0650\n",
      "Epoch [29/200], Loss: 0.0656\n",
      "Epoch [30/200], Loss: 0.0694\n",
      "Epoch [31/200], Loss: 0.0635\n",
      "Epoch [32/200], Loss: 0.0639\n",
      "Epoch [33/200], Loss: 0.0656\n",
      "Epoch [34/200], Loss: 0.0624\n",
      "Epoch [35/200], Loss: 0.0656\n",
      "Epoch [36/200], Loss: 0.0649\n",
      "Epoch [37/200], Loss: 0.0642\n",
      "Epoch [38/200], Loss: 0.0658\n",
      "Epoch [39/200], Loss: 0.0632\n",
      "Epoch [40/200], Loss: 0.0627\n",
      "Epoch [41/200], Loss: 0.0650\n",
      "Epoch [42/200], Loss: 0.0631\n",
      "Epoch [43/200], Loss: 0.0663\n",
      "Epoch [44/200], Loss: 0.0616\n",
      "Epoch [45/200], Loss: 0.0599\n",
      "Epoch [46/200], Loss: 0.0645\n",
      "Epoch [47/200], Loss: 0.0605\n",
      "Epoch [48/200], Loss: 0.0602\n",
      "Epoch [49/200], Loss: 0.0616\n",
      "Epoch [50/200], Loss: 0.0598\n",
      "Epoch [51/200], Loss: 0.0600\n",
      "Epoch [52/200], Loss: 0.0565\n",
      "Epoch [53/200], Loss: 0.0577\n",
      "Epoch [54/200], Loss: 0.0574\n",
      "Epoch [55/200], Loss: 0.0588\n",
      "Epoch [56/200], Loss: 0.0590\n",
      "Epoch [57/200], Loss: 0.0580\n",
      "Epoch [58/200], Loss: 0.0598\n",
      "Epoch [59/200], Loss: 0.0612\n",
      "Epoch [60/200], Loss: 0.0567\n",
      "Epoch [61/200], Loss: 0.0590\n",
      "Epoch [62/200], Loss: 0.0591\n",
      "Epoch [63/200], Loss: 0.0553\n",
      "Epoch [64/200], Loss: 0.0584\n",
      "Epoch [65/200], Loss: 0.0609\n",
      "Epoch [66/200], Loss: 0.0579\n",
      "Epoch [67/200], Loss: 0.0611\n",
      "Epoch [68/200], Loss: 0.0582\n",
      "Epoch [69/200], Loss: 0.0579\n",
      "Epoch [70/200], Loss: 0.0603\n",
      "Epoch [71/200], Loss: 0.0581\n",
      "Epoch [72/200], Loss: 0.0575\n",
      "Epoch [73/200], Loss: 0.0589\n",
      "Epoch [74/200], Loss: 0.0553\n",
      "Epoch [75/200], Loss: 0.0568\n",
      "Epoch [76/200], Loss: 0.0592\n",
      "Epoch [77/200], Loss: 0.0563\n",
      "Epoch [78/200], Loss: 0.0615\n",
      "Epoch [79/200], Loss: 0.0579\n",
      "Epoch [80/200], Loss: 0.0563\n",
      "Epoch [81/200], Loss: 0.0590\n",
      "Epoch [82/200], Loss: 0.0588\n",
      "Epoch [83/200], Loss: 0.0568\n",
      "Epoch [84/200], Loss: 0.0580\n",
      "Epoch [85/200], Loss: 0.0548\n",
      "Epoch [86/200], Loss: 0.0573\n",
      "Epoch [87/200], Loss: 0.0567\n",
      "Epoch [88/200], Loss: 0.0570\n",
      "Epoch [89/200], Loss: 0.0567\n",
      "Epoch [90/200], Loss: 0.0562\n",
      "Epoch [91/200], Loss: 0.0560\n",
      "Epoch [92/200], Loss: 0.0569\n",
      "Epoch [93/200], Loss: 0.0552\n",
      "Epoch [94/200], Loss: 0.0535\n",
      "Epoch [95/200], Loss: 0.0553\n",
      "Epoch [96/200], Loss: 0.0528\n",
      "Epoch [97/200], Loss: 0.0507\n",
      "Epoch [98/200], Loss: 0.0526\n",
      "Epoch [99/200], Loss: 0.0535\n",
      "Epoch [100/200], Loss: 0.0510\n",
      "Epoch [101/200], Loss: 0.0551\n",
      "Epoch [102/200], Loss: 0.0552\n",
      "Epoch [103/200], Loss: 0.0544\n",
      "Epoch [104/200], Loss: 0.0552\n",
      "Epoch [105/200], Loss: 0.0563\n",
      "Epoch [106/200], Loss: 0.0540\n",
      "Epoch [107/200], Loss: 0.0566\n",
      "Epoch [108/200], Loss: 0.0555\n",
      "Epoch [109/200], Loss: 0.0547\n",
      "Epoch [110/200], Loss: 0.0556\n",
      "Epoch [111/200], Loss: 0.0529\n",
      "Epoch [112/200], Loss: 0.0529\n",
      "Epoch [113/200], Loss: 0.0541\n",
      "Epoch [114/200], Loss: 0.0513\n",
      "Epoch [115/200], Loss: 0.0542\n",
      "Epoch [116/200], Loss: 0.0563\n",
      "Epoch [117/200], Loss: 0.0546\n",
      "Epoch [118/200], Loss: 0.0547\n",
      "Epoch [119/200], Loss: 0.0509\n",
      "Epoch [120/200], Loss: 0.0498\n",
      "Epoch [121/200], Loss: 0.0524\n",
      "Epoch [122/200], Loss: 0.0493\n",
      "Epoch [123/200], Loss: 0.0531\n",
      "Epoch [124/200], Loss: 0.0540\n",
      "Epoch [125/200], Loss: 0.0525\n",
      "Epoch [126/200], Loss: 0.0543\n",
      "Epoch [127/200], Loss: 0.0538\n",
      "Epoch [128/200], Loss: 0.0524\n",
      "Epoch [129/200], Loss: 0.0529\n",
      "Epoch [130/200], Loss: 0.0511\n",
      "Epoch [131/200], Loss: 0.0508\n",
      "Epoch [132/200], Loss: 0.0521\n",
      "Epoch [133/200], Loss: 0.0509\n",
      "Epoch [134/200], Loss: 0.0518\n",
      "Epoch [135/200], Loss: 0.0512\n",
      "Epoch [136/200], Loss: 0.0491\n",
      "Epoch [137/200], Loss: 0.0527\n",
      "Epoch [138/200], Loss: 0.0506\n",
      "Epoch [139/200], Loss: 0.0520\n",
      "Epoch [140/200], Loss: 0.0507\n",
      "Epoch [141/200], Loss: 0.0492\n",
      "Epoch [142/200], Loss: 0.0480\n",
      "Epoch [143/200], Loss: 0.0510\n",
      "Epoch [144/200], Loss: 0.0508\n",
      "Epoch [145/200], Loss: 0.0507\n",
      "Epoch [146/200], Loss: 0.0530\n",
      "Epoch [147/200], Loss: 0.0503\n",
      "Epoch [148/200], Loss: 0.0511\n",
      "Epoch [149/200], Loss: 0.0543\n",
      "Epoch [150/200], Loss: 0.0510\n",
      "Epoch [151/200], Loss: 0.0515\n",
      "Epoch [152/200], Loss: 0.0509\n",
      "Epoch [153/200], Loss: 0.0483\n",
      "Epoch [154/200], Loss: 0.0493\n",
      "Epoch [155/200], Loss: 0.0503\n",
      "Epoch [156/200], Loss: 0.0486\n",
      "Epoch [157/200], Loss: 0.0517\n",
      "Epoch [158/200], Loss: 0.0496\n",
      "Epoch [159/200], Loss: 0.0469\n",
      "Epoch [160/200], Loss: 0.0500\n",
      "Epoch [161/200], Loss: 0.0482\n",
      "Epoch [162/200], Loss: 0.0483\n",
      "Epoch [163/200], Loss: 0.0495\n",
      "Epoch [164/200], Loss: 0.0470\n",
      "Epoch [165/200], Loss: 0.0466\n",
      "Epoch [166/200], Loss: 0.0488\n",
      "Epoch [167/200], Loss: 0.0470\n",
      "Epoch [168/200], Loss: 0.0486\n",
      "Epoch [169/200], Loss: 0.0508\n",
      "Epoch [170/200], Loss: 0.0475\n",
      "Epoch [171/200], Loss: 0.0482\n",
      "Epoch [172/200], Loss: 0.0488\n",
      "Epoch [173/200], Loss: 0.0481\n",
      "Epoch [174/200], Loss: 0.0478\n",
      "Epoch [175/200], Loss: 0.0495\n",
      "Epoch [176/200], Loss: 0.0475\n",
      "Epoch [177/200], Loss: 0.0483\n",
      "Epoch [178/200], Loss: 0.0462\n",
      "Epoch [179/200], Loss: 0.0476\n",
      "Epoch [180/200], Loss: 0.0492\n",
      "Epoch [181/200], Loss: 0.0467\n",
      "Epoch [182/200], Loss: 0.0471\n",
      "Epoch [183/200], Loss: 0.0466\n",
      "Epoch [184/200], Loss: 0.0462\n",
      "Epoch [185/200], Loss: 0.0477\n",
      "Epoch [186/200], Loss: 0.0504\n",
      "Epoch [187/200], Loss: 0.0473\n",
      "Epoch [188/200], Loss: 0.0482\n",
      "Epoch [189/200], Loss: 0.0477\n",
      "Epoch [190/200], Loss: 0.0464\n",
      "Epoch [191/200], Loss: 0.0474\n",
      "Epoch [192/200], Loss: 0.0488\n",
      "Epoch [193/200], Loss: 0.0452\n",
      "Epoch [194/200], Loss: 0.0481\n",
      "Epoch [195/200], Loss: 0.0472\n",
      "Epoch [196/200], Loss: 0.0471\n",
      "Epoch [197/200], Loss: 0.0474\n",
      "Epoch [198/200], Loss: 0.0437\n",
      "Epoch [199/200], Loss: 0.0456\n",
      "Epoch [200/200], Loss: 0.0469\n"
     ]
    }
   ],
   "source": [
    "trainer.train(num_epochs=200)\n",
    "num_test_samples = len(test_dl.dataset)\n",
    "latents = torch.nn.Parameter(torch.randn(num_test_samples, trainer.latent_dim).to(device))\n",
    "opt = optim.Adam([latents], lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6568406b-c6c5-40af-9339-9825107b7bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AD has finished test evaluation with a test loss of 0.1657548677176237.\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluate_model(model=decoder, test_dl=test_dl, opt=opt, latents=latents, epochs=1000, device=device)\n",
    "print(f\"AD has finished test evaluation with a test loss of {test_loss}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad556234-27db-4273-b409-cc4d0380268a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled Vectors Shape: torch.Size([5, 256])\n",
      "Random Vectors Shape: torch.Size([5, 256])\n",
      "Sampled Images Shape: torch.Size([5, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Randomly sample 5 indices from the test dataset\n",
    "random.seed(6)\n",
    "sampled_indices = random.sample(range(len(latents)), 5)\n",
    "\n",
    "# Extract the corresponding vectors (input data) and their labels\n",
    "sampled_latents = [latents[i] for i in sampled_indices]  # Only selecting input data, not labels\n",
    "\n",
    "# Convert to a single tensor (optional)\n",
    "sampled_latents_tensor = torch.stack(sampled_latents)\n",
    "random_latents_tensor = torch.randn_like(sampled_latents_tensor)\n",
    "\n",
    "print(\"Sampled Vectors Shape:\", sampled_latents_tensor.shape)  # Should be (5, *) depending on your data shape\n",
    "print(\"Random Vectors Shape:\", random_latents_tensor.shape)  # Should be (5, *) depending on your data shape\n",
    "\n",
    "sampled_test_images = decoder(sampled_latents_tensor).view(-1, 1, 28, 28)\n",
    "random_test_images = decoder(random_latents_tensor).view(-1, 1, 28, 28)\n",
    "\n",
    "print(\"Sampled Images Shape:\", sampled_test_images.shape)  # Should be (5, *) depending on your data shape\n",
    "utils.save_images(sampled_test_images, \"sampled_test_images.png\")\n",
    "utils.save_images(random_test_images, \"random_test_images.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
