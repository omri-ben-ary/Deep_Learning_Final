{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04bb3860-f4ed-4dc2-bb65-fd5bab45d709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from VariationalAutoDecoder_LogNormal import VariationalAutoDecoder as VAD_LogNormal\n",
    "from VAD_Trainer import VAD_Trainer\n",
    "import utils\n",
    "from evaluate import evaluate_model\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d227682-fe2c-4635-8f22-43695ac358ee",
   "metadata": {},
   "source": [
    "## Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb85c21c-5862-401b-88a4-e20796edf5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, train_dl, test_ds, test_dl = utils.create_dataloaders(data_path=\"dataset\" ,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c9b43a-4434-4820-92c0-caf522961bb1",
   "metadata": {},
   "source": [
    "## Train Auto Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb06f910-ca78-4244-9055-91cfcf343f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dims = [16, 32, 64, 128]\n",
    "betas = [1e5, 5e5, 1e6, 5e6]\n",
    "VADs = [VAD_LogNormal(latent_dim=dim, device=device) for (dim,_) in list(itertools.product(latent_dims, betas))]\n",
    "trainers = [VAD_Trainer(var_decoder=VADs[i], dataloader=train_dl, latent_dim=dim, beta=beta, device=device, lr=1e-3)\n",
    "            for i,(dim,beta) in enumerate(list(itertools.product(latent_dims, betas)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13baccde-a05f-4922-b4b9-681d7aecfc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = len(train_dl.dataset)\n",
    "csv_file_path = 'results_VAD_LogNormal.csv'\n",
    "\n",
    "with open(csv_file_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    header = ['Index'] + [f'Epoch {i+1} Loss' for i in range(500)] + ['Final Train Loss']\n",
    "    writer.writerow(header)\n",
    "\n",
    "for index, trainer in enumerate(trainers):\n",
    "    optimizer = optim.Adam([trainer.latents], lr=1e-3)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_loss = trainer.train(num_epochs=500)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Trainer {index} has finished training in {elapsed_time:.2f} seconds.\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_eval_loss = evaluate_model(model=VADs[index], test_dl=train_dl, opt=optimizer, latents=trainer.latents, epochs=500, device=device) \n",
    "    end_time = time.time()\n",
    "    \n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"AD {index} has finished train evaluation in {elapsed_time:.2f} seconds.\")\n",
    "\n",
    "    row = [index] + train_loss + [train_eval_loss]\n",
    "\n",
    "    with open(csv_file_path, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"Results saved to {csv_file_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27147e64-6c63-4528-bc12-99750ba8ccae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(trainers)):\n",
    "    latents = VADs[i].reparameterize(trainers[i].latents)\n",
    "    utils.plot_tsne(train_ds, latents, f\"tsne_LogNormal_{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd033aaf-061c-4bd6-b32e-40466dd1027f",
   "metadata": {},
   "source": [
    "## Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc862a48-c47c-49ce-b233-71192301ee15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 734228004.0000\n",
      "Epoch [2/1000], Loss: 718163696.0000\n",
      "Epoch [3/1000], Loss: 706738972.0000\n",
      "Epoch [4/1000], Loss: 696464196.0000\n",
      "Epoch [5/1000], Loss: 686938036.0000\n",
      "Epoch [6/1000], Loss: 677938344.0000\n",
      "Epoch [7/1000], Loss: 669048624.0000\n",
      "Epoch [8/1000], Loss: 660823300.0000\n",
      "Epoch [9/1000], Loss: 652712308.0000\n",
      "Epoch [10/1000], Loss: 645056568.0000\n",
      "Epoch [11/1000], Loss: 637641864.0000\n",
      "Epoch [12/1000], Loss: 630427548.0000\n",
      "Epoch [13/1000], Loss: 623641948.0000\n",
      "Epoch [14/1000], Loss: 616896844.0000\n",
      "Epoch [15/1000], Loss: 610328472.0000\n",
      "Epoch [16/1000], Loss: 603981192.0000\n",
      "Epoch [17/1000], Loss: 597757456.0000\n",
      "Epoch [18/1000], Loss: 591706048.0000\n",
      "Epoch [19/1000], Loss: 585798740.0000\n",
      "Epoch [20/1000], Loss: 579979968.0000\n",
      "Epoch [21/1000], Loss: 574275000.0000\n",
      "Epoch [22/1000], Loss: 568770268.0000\n",
      "Epoch [23/1000], Loss: 563209960.0000\n",
      "Epoch [24/1000], Loss: 557831800.0000\n",
      "Epoch [25/1000], Loss: 552558460.0000\n",
      "Epoch [26/1000], Loss: 547353888.0000\n",
      "Epoch [27/1000], Loss: 542205528.0000\n",
      "Epoch [28/1000], Loss: 537137536.0000\n",
      "Epoch [29/1000], Loss: 532174398.0000\n",
      "Epoch [30/1000], Loss: 527283954.0000\n",
      "Epoch [31/1000], Loss: 522483212.0000\n",
      "Epoch [32/1000], Loss: 517806554.0000\n",
      "Epoch [33/1000], Loss: 513049924.0000\n",
      "Epoch [34/1000], Loss: 508462654.0000\n",
      "Epoch [35/1000], Loss: 503943912.0000\n",
      "Epoch [36/1000], Loss: 499468290.0000\n",
      "Epoch [37/1000], Loss: 495084210.0000\n",
      "Epoch [38/1000], Loss: 490734002.0000\n",
      "Epoch [39/1000], Loss: 486376920.0000\n",
      "Epoch [40/1000], Loss: 482159506.0000\n",
      "Epoch [41/1000], Loss: 477967494.0000\n",
      "Epoch [42/1000], Loss: 473876254.0000\n",
      "Epoch [43/1000], Loss: 469752746.0000\n",
      "Epoch [44/1000], Loss: 465719266.0000\n",
      "Epoch [45/1000], Loss: 461847870.0000\n",
      "Epoch [46/1000], Loss: 457889194.0000\n",
      "Epoch [47/1000], Loss: 453908548.0000\n",
      "Epoch [48/1000], Loss: 450085570.0000\n",
      "Epoch [49/1000], Loss: 446275410.0000\n",
      "Epoch [50/1000], Loss: 442483744.0000\n",
      "Epoch [51/1000], Loss: 438772690.0000\n",
      "Epoch [52/1000], Loss: 435139482.0000\n",
      "Epoch [53/1000], Loss: 431496816.0000\n",
      "Epoch [54/1000], Loss: 427916054.0000\n",
      "Epoch [55/1000], Loss: 424367820.0000\n",
      "Epoch [56/1000], Loss: 420861330.0000\n",
      "Epoch [57/1000], Loss: 417390770.0000\n",
      "Epoch [58/1000], Loss: 413945446.0000\n",
      "Epoch [59/1000], Loss: 410564852.0000\n",
      "Epoch [60/1000], Loss: 407204724.0000\n",
      "Epoch [61/1000], Loss: 403850872.0000\n",
      "Epoch [62/1000], Loss: 400568736.0000\n",
      "Epoch [63/1000], Loss: 397290494.0000\n",
      "Epoch [64/1000], Loss: 394079272.0000\n",
      "Epoch [65/1000], Loss: 390876996.0000\n",
      "Epoch [66/1000], Loss: 387728930.0000\n",
      "Epoch [67/1000], Loss: 384618648.0000\n",
      "Epoch [68/1000], Loss: 381506890.0000\n",
      "Epoch [69/1000], Loss: 378434114.0000\n",
      "Epoch [70/1000], Loss: 375430976.0000\n",
      "Epoch [71/1000], Loss: 372436188.0000\n",
      "Epoch [72/1000], Loss: 369454710.0000\n",
      "Epoch [73/1000], Loss: 366452006.0000\n",
      "Epoch [74/1000], Loss: 363581638.0000\n",
      "Epoch [75/1000], Loss: 360646610.0000\n",
      "Epoch [76/1000], Loss: 357822712.0000\n",
      "Epoch [77/1000], Loss: 354951298.0000\n",
      "Epoch [78/1000], Loss: 352162358.0000\n",
      "Epoch [79/1000], Loss: 349367096.0000\n",
      "Epoch [80/1000], Loss: 346629780.0000\n",
      "Epoch [81/1000], Loss: 343837638.0000\n",
      "Epoch [82/1000], Loss: 341142550.0000\n",
      "Epoch [83/1000], Loss: 338489968.0000\n",
      "Epoch [84/1000], Loss: 335810516.0000\n",
      "Epoch [85/1000], Loss: 333161920.0000\n",
      "Epoch [86/1000], Loss: 330594988.0000\n",
      "Epoch [87/1000], Loss: 327974996.0000\n",
      "Epoch [88/1000], Loss: 325421968.0000\n",
      "Epoch [89/1000], Loss: 322908566.0000\n",
      "Epoch [90/1000], Loss: 320303678.0000\n",
      "Epoch [91/1000], Loss: 317975728.0000\n",
      "Epoch [92/1000], Loss: 315369166.0000\n",
      "Epoch [93/1000], Loss: 312897974.0000\n",
      "Epoch [94/1000], Loss: 310501200.0000\n",
      "Epoch [95/1000], Loss: 308126028.0000\n",
      "Epoch [96/1000], Loss: 305700140.0000\n",
      "Epoch [97/1000], Loss: 303303638.0000\n",
      "Epoch [98/1000], Loss: 300977714.0000\n",
      "Epoch [99/1000], Loss: 298606684.0000\n",
      "Epoch [100/1000], Loss: 296339716.0000\n",
      "Epoch [101/1000], Loss: 294039634.0000\n",
      "Epoch [102/1000], Loss: 291754930.0000\n",
      "Epoch [103/1000], Loss: 289531144.0000\n",
      "Epoch [104/1000], Loss: 287285660.0000\n",
      "Epoch [105/1000], Loss: 285025596.0000\n",
      "Epoch [106/1000], Loss: 282873940.0000\n",
      "Epoch [107/1000], Loss: 280669116.0000\n",
      "Epoch [108/1000], Loss: 278527510.0000\n",
      "Epoch [109/1000], Loss: 276371910.0000\n",
      "Epoch [110/1000], Loss: 274262603.0000\n",
      "Epoch [111/1000], Loss: 272121433.0000\n",
      "Epoch [112/1000], Loss: 270073991.0000\n",
      "Epoch [113/1000], Loss: 267961404.0000\n",
      "Epoch [114/1000], Loss: 265858656.0000\n",
      "Epoch [115/1000], Loss: 263926504.0000\n",
      "Epoch [116/1000], Loss: 261886464.0000\n",
      "Epoch [117/1000], Loss: 259801840.0000\n",
      "Epoch [118/1000], Loss: 257828804.0000\n",
      "Epoch [119/1000], Loss: 255888462.0000\n",
      "Epoch [120/1000], Loss: 253952757.0000\n",
      "Epoch [121/1000], Loss: 251935412.0000\n",
      "Epoch [122/1000], Loss: 250056969.0000\n",
      "Epoch [123/1000], Loss: 248178644.0000\n",
      "Epoch [124/1000], Loss: 246346187.0000\n",
      "Epoch [125/1000], Loss: 244407062.0000\n",
      "Epoch [126/1000], Loss: 242544157.0000\n",
      "Epoch [127/1000], Loss: 240651336.0000\n",
      "Epoch [128/1000], Loss: 238876408.0000\n",
      "Epoch [129/1000], Loss: 236953837.0000\n",
      "Epoch [130/1000], Loss: 235164229.0000\n",
      "Epoch [131/1000], Loss: 233415945.0000\n",
      "Epoch [132/1000], Loss: 231620884.0000\n",
      "Epoch [133/1000], Loss: 229813547.0000\n",
      "Epoch [134/1000], Loss: 228115897.0000\n",
      "Epoch [135/1000], Loss: 226359407.0000\n",
      "Epoch [136/1000], Loss: 224646034.0000\n",
      "Epoch [137/1000], Loss: 222954694.0000\n",
      "Epoch [138/1000], Loss: 221258220.0000\n",
      "Epoch [139/1000], Loss: 219561019.0000\n",
      "Epoch [140/1000], Loss: 217957198.0000\n",
      "Epoch [141/1000], Loss: 216326878.0000\n",
      "Epoch [142/1000], Loss: 214580473.0000\n",
      "Epoch [143/1000], Loss: 212958253.0000\n",
      "Epoch [144/1000], Loss: 211405128.0000\n",
      "Epoch [145/1000], Loss: 209755278.0000\n",
      "Epoch [146/1000], Loss: 208139411.0000\n",
      "Epoch [147/1000], Loss: 206557531.0000\n",
      "Epoch [148/1000], Loss: 204985158.0000\n",
      "Epoch [149/1000], Loss: 203473996.0000\n",
      "Epoch [150/1000], Loss: 201871061.0000\n",
      "Epoch [151/1000], Loss: 200443040.0000\n",
      "Epoch [152/1000], Loss: 198899530.0000\n",
      "Epoch [153/1000], Loss: 197345913.0000\n",
      "Epoch [154/1000], Loss: 195878391.0000\n",
      "Epoch [155/1000], Loss: 194359741.0000\n",
      "Epoch [156/1000], Loss: 192900574.0000\n",
      "Epoch [157/1000], Loss: 191405609.0000\n",
      "Epoch [158/1000], Loss: 190031434.0000\n",
      "Epoch [159/1000], Loss: 188534332.0000\n",
      "Epoch [160/1000], Loss: 187074767.0000\n",
      "Epoch [161/1000], Loss: 185694478.0000\n",
      "Epoch [162/1000], Loss: 184269819.0000\n",
      "Epoch [163/1000], Loss: 182854941.0000\n",
      "Epoch [164/1000], Loss: 181669836.0000\n",
      "Epoch [165/1000], Loss: 180096451.0000\n",
      "Epoch [166/1000], Loss: 178783433.0000\n",
      "Epoch [167/1000], Loss: 177380365.0000\n",
      "Epoch [168/1000], Loss: 176019928.0000\n",
      "Epoch [169/1000], Loss: 174636057.0000\n",
      "Epoch [170/1000], Loss: 173382081.0000\n",
      "Epoch [171/1000], Loss: 172038366.0000\n",
      "Epoch [172/1000], Loss: 170746516.0000\n",
      "Epoch [173/1000], Loss: 169474052.0000\n",
      "Epoch [174/1000], Loss: 168202066.0000\n",
      "Epoch [175/1000], Loss: 167020239.0000\n",
      "Epoch [176/1000], Loss: 165625500.0000\n",
      "Epoch [177/1000], Loss: 164385327.0000\n",
      "Epoch [178/1000], Loss: 163102253.0000\n",
      "Epoch [179/1000], Loss: 161893688.0000\n",
      "Epoch [180/1000], Loss: 160658732.0000\n",
      "Epoch [181/1000], Loss: 159427099.0000\n",
      "Epoch [182/1000], Loss: 158257616.0000\n",
      "Epoch [183/1000], Loss: 157003625.0000\n",
      "Epoch [184/1000], Loss: 155813401.0000\n",
      "Epoch [185/1000], Loss: 154661535.0000\n",
      "Epoch [186/1000], Loss: 153474259.0000\n",
      "Epoch [187/1000], Loss: 152270432.0000\n",
      "Epoch [188/1000], Loss: 151179083.0000\n",
      "Epoch [189/1000], Loss: 149984194.0000\n",
      "Epoch [190/1000], Loss: 148852268.0000\n",
      "Epoch [191/1000], Loss: 147735341.0000\n",
      "Epoch [192/1000], Loss: 146579031.0000\n",
      "Epoch [193/1000], Loss: 145503908.0000\n",
      "Epoch [194/1000], Loss: 144354605.0000\n",
      "Epoch [195/1000], Loss: 143253090.0000\n",
      "Epoch [196/1000], Loss: 142304949.0000\n",
      "Epoch [197/1000], Loss: 141100407.0000\n",
      "Epoch [198/1000], Loss: 140117153.0000\n",
      "Epoch [199/1000], Loss: 138961854.0000\n",
      "Epoch [200/1000], Loss: 137964966.0000\n",
      "Epoch [201/1000], Loss: 136846154.5000\n",
      "Epoch [202/1000], Loss: 135780504.5000\n",
      "Epoch [203/1000], Loss: 134768109.0000\n",
      "Epoch [204/1000], Loss: 133782423.0000\n",
      "Epoch [205/1000], Loss: 132787621.5000\n",
      "Epoch [206/1000], Loss: 131715299.5000\n",
      "Epoch [207/1000], Loss: 130735948.0000\n",
      "Epoch [208/1000], Loss: 129707417.5000\n",
      "Epoch [209/1000], Loss: 128770058.5000\n",
      "Epoch [210/1000], Loss: 127746956.5000\n",
      "Epoch [211/1000], Loss: 126715840.5000\n",
      "Epoch [212/1000], Loss: 125846036.0000\n",
      "Epoch [213/1000], Loss: 124820243.0000\n",
      "Epoch [214/1000], Loss: 123890751.0000\n",
      "Epoch [215/1000], Loss: 122916119.0000\n",
      "Epoch [216/1000], Loss: 122103810.0000\n",
      "Epoch [217/1000], Loss: 121071014.0000\n",
      "Epoch [218/1000], Loss: 120076510.0000\n",
      "Epoch [219/1000], Loss: 119226521.0000\n",
      "Epoch [220/1000], Loss: 118290679.5000\n",
      "Epoch [221/1000], Loss: 117494920.0000\n",
      "Epoch [222/1000], Loss: 116513662.5000\n",
      "Epoch [223/1000], Loss: 115609692.0000\n",
      "Epoch [224/1000], Loss: 114722731.5000\n",
      "Epoch [225/1000], Loss: 113848254.5000\n",
      "Epoch [226/1000], Loss: 112937645.0000\n",
      "Epoch [227/1000], Loss: 112198541.0000\n",
      "Epoch [228/1000], Loss: 111279617.0000\n",
      "Epoch [229/1000], Loss: 110392686.0000\n",
      "Epoch [230/1000], Loss: 109562572.0000\n",
      "Epoch [231/1000], Loss: 108686767.5000\n",
      "Epoch [232/1000], Loss: 107840700.0000\n",
      "Epoch [233/1000], Loss: 107030486.0000\n",
      "Epoch [234/1000], Loss: 106216982.0000\n",
      "Epoch [235/1000], Loss: 105441377.5000\n",
      "Epoch [236/1000], Loss: 104622678.5000\n",
      "Epoch [237/1000], Loss: 103744305.0000\n",
      "Epoch [238/1000], Loss: 102963053.0000\n",
      "Epoch [239/1000], Loss: 102219669.5000\n",
      "Epoch [240/1000], Loss: 101408114.0000\n",
      "Epoch [241/1000], Loss: 100663983.0000\n",
      "Epoch [242/1000], Loss: 99883491.5000\n",
      "Epoch [243/1000], Loss: 99124021.5000\n",
      "Epoch [244/1000], Loss: 98323329.0000\n",
      "Epoch [245/1000], Loss: 97543676.0000\n",
      "Epoch [246/1000], Loss: 96807573.5000\n",
      "Epoch [247/1000], Loss: 96078626.0000\n",
      "Epoch [248/1000], Loss: 95303104.0000\n",
      "Epoch [249/1000], Loss: 94562740.0000\n",
      "Epoch [250/1000], Loss: 93862465.0000\n",
      "Epoch [251/1000], Loss: 93164670.5000\n",
      "Epoch [252/1000], Loss: 92441026.5000\n",
      "Epoch [253/1000], Loss: 91674000.0000\n",
      "Epoch [254/1000], Loss: 91041492.0000\n",
      "Epoch [255/1000], Loss: 90331466.0000\n",
      "Epoch [256/1000], Loss: 89604995.5000\n",
      "Epoch [257/1000], Loss: 88876858.0000\n",
      "Epoch [258/1000], Loss: 88243084.5000\n",
      "Epoch [259/1000], Loss: 87500713.5000\n",
      "Epoch [260/1000], Loss: 86865389.0000\n",
      "Epoch [261/1000], Loss: 86208344.0000\n",
      "Epoch [262/1000], Loss: 85510799.5000\n",
      "Epoch [263/1000], Loss: 84889250.0000\n",
      "Epoch [264/1000], Loss: 84205157.0000\n",
      "Epoch [265/1000], Loss: 83494039.0000\n",
      "Epoch [266/1000], Loss: 82925089.5000\n",
      "Epoch [267/1000], Loss: 82218184.0000\n",
      "Epoch [268/1000], Loss: 81654152.0000\n",
      "Epoch [269/1000], Loss: 81006102.5000\n",
      "Epoch [270/1000], Loss: 80398897.0000\n",
      "Epoch [271/1000], Loss: 79780157.5000\n",
      "Epoch [272/1000], Loss: 79140100.5000\n",
      "Epoch [273/1000], Loss: 78583318.0000\n",
      "Epoch [274/1000], Loss: 77912141.0000\n",
      "Epoch [275/1000], Loss: 77330199.0000\n",
      "Epoch [276/1000], Loss: 76710130.5000\n",
      "Epoch [277/1000], Loss: 76119157.0000\n",
      "Epoch [278/1000], Loss: 75489340.0000\n",
      "Epoch [279/1000], Loss: 74893336.5000\n",
      "Epoch [280/1000], Loss: 74321608.0000\n",
      "Epoch [281/1000], Loss: 73770215.0000\n",
      "Epoch [282/1000], Loss: 73177967.5000\n",
      "Epoch [283/1000], Loss: 72633421.5000\n",
      "Epoch [284/1000], Loss: 72054679.5000\n",
      "Epoch [285/1000], Loss: 71535579.5000\n",
      "Epoch [286/1000], Loss: 70947923.5000\n",
      "Epoch [287/1000], Loss: 70395887.2500\n",
      "Epoch [288/1000], Loss: 69857156.2500\n",
      "Epoch [289/1000], Loss: 69296183.2500\n",
      "Epoch [290/1000], Loss: 68720355.7500\n",
      "Epoch [291/1000], Loss: 68224906.0000\n",
      "Epoch [292/1000], Loss: 67648739.7500\n",
      "Epoch [293/1000], Loss: 67179916.5000\n",
      "Epoch [294/1000], Loss: 66660132.7500\n",
      "Epoch [295/1000], Loss: 66128582.0000\n",
      "Epoch [296/1000], Loss: 65576774.2500\n",
      "Epoch [297/1000], Loss: 65061298.0000\n",
      "Epoch [298/1000], Loss: 64570557.0000\n",
      "Epoch [299/1000], Loss: 64100347.0000\n",
      "Epoch [300/1000], Loss: 63585854.7500\n",
      "Epoch [301/1000], Loss: 63071959.5000\n",
      "Epoch [302/1000], Loss: 62639336.2500\n",
      "Epoch [303/1000], Loss: 62069351.2500\n",
      "Epoch [304/1000], Loss: 61629472.5000\n",
      "Epoch [305/1000], Loss: 61166426.2500\n",
      "Epoch [306/1000], Loss: 60710106.7500\n",
      "Epoch [307/1000], Loss: 60169178.2500\n",
      "Epoch [308/1000], Loss: 59741569.7500\n",
      "Epoch [309/1000], Loss: 59248145.7500\n",
      "Epoch [310/1000], Loss: 58794575.5000\n",
      "Epoch [311/1000], Loss: 58351794.2500\n",
      "Epoch [312/1000], Loss: 57864296.7500\n",
      "Epoch [313/1000], Loss: 57479144.2500\n",
      "Epoch [314/1000], Loss: 57022022.5000\n",
      "Epoch [315/1000], Loss: 56528796.2500\n",
      "Epoch [316/1000], Loss: 56093151.5000\n",
      "Epoch [317/1000], Loss: 55665638.5000\n",
      "Epoch [318/1000], Loss: 55223456.2500\n",
      "Epoch [319/1000], Loss: 54764582.7500\n",
      "Epoch [320/1000], Loss: 54372312.7500\n",
      "Epoch [321/1000], Loss: 53958289.7500\n",
      "Epoch [322/1000], Loss: 53525233.2500\n",
      "Epoch [323/1000], Loss: 53120245.5000\n",
      "Epoch [324/1000], Loss: 52709353.2500\n",
      "Epoch [325/1000], Loss: 52301739.5000\n",
      "Epoch [326/1000], Loss: 51861256.7500\n",
      "Epoch [327/1000], Loss: 51466644.7500\n",
      "Epoch [328/1000], Loss: 51071816.0000\n",
      "Epoch [329/1000], Loss: 50679992.5000\n",
      "Epoch [330/1000], Loss: 50230096.5000\n",
      "Epoch [331/1000], Loss: 49855686.5000\n",
      "Epoch [332/1000], Loss: 49480639.2500\n",
      "Epoch [333/1000], Loss: 49086609.2500\n",
      "Epoch [334/1000], Loss: 48719217.5000\n",
      "Epoch [335/1000], Loss: 48326570.7500\n",
      "Epoch [336/1000], Loss: 47978432.5000\n",
      "Epoch [337/1000], Loss: 47597486.5000\n",
      "Epoch [338/1000], Loss: 47235070.7500\n",
      "Epoch [339/1000], Loss: 46833711.5000\n",
      "Epoch [340/1000], Loss: 46504122.2500\n",
      "Epoch [341/1000], Loss: 46135454.0000\n",
      "Epoch [342/1000], Loss: 45760625.0000\n",
      "Epoch [343/1000], Loss: 45398278.7500\n",
      "Epoch [344/1000], Loss: 45082910.5000\n",
      "Epoch [345/1000], Loss: 44683537.7500\n",
      "Epoch [346/1000], Loss: 44307679.2500\n",
      "Epoch [347/1000], Loss: 44007352.2500\n",
      "Epoch [348/1000], Loss: 43642294.7500\n",
      "Epoch [349/1000], Loss: 43343823.7500\n",
      "Epoch [350/1000], Loss: 42996599.2500\n",
      "Epoch [351/1000], Loss: 42630670.0000\n",
      "Epoch [352/1000], Loss: 42303069.0000\n",
      "Epoch [353/1000], Loss: 41966175.2500\n",
      "Epoch [354/1000], Loss: 41650639.7500\n",
      "Epoch [355/1000], Loss: 41323826.2500\n",
      "Epoch [356/1000], Loss: 41012089.0000\n",
      "Epoch [357/1000], Loss: 40707314.0000\n",
      "Epoch [358/1000], Loss: 40352991.5000\n",
      "Epoch [359/1000], Loss: 40036473.0000\n",
      "Epoch [360/1000], Loss: 39749630.7500\n",
      "Epoch [361/1000], Loss: 39468677.5000\n",
      "Epoch [362/1000], Loss: 39123000.2500\n",
      "Epoch [363/1000], Loss: 38833945.0000\n",
      "Epoch [364/1000], Loss: 38511140.7500\n",
      "Epoch [365/1000], Loss: 38194886.0000\n",
      "Epoch [366/1000], Loss: 37890834.5000\n",
      "Epoch [367/1000], Loss: 37627189.0000\n",
      "Epoch [368/1000], Loss: 37301628.7500\n",
      "Epoch [369/1000], Loss: 37050128.0000\n",
      "Epoch [370/1000], Loss: 36734439.0000\n",
      "Epoch [371/1000], Loss: 36455089.0000\n",
      "Epoch [372/1000], Loss: 36190707.0000\n",
      "Epoch [373/1000], Loss: 35888842.0000\n",
      "Epoch [374/1000], Loss: 35682595.6250\n",
      "Epoch [375/1000], Loss: 35316249.0000\n",
      "Epoch [376/1000], Loss: 35122461.7500\n",
      "Epoch [377/1000], Loss: 34803159.3750\n",
      "Epoch [378/1000], Loss: 34525508.7500\n",
      "Epoch [379/1000], Loss: 34293444.3750\n",
      "Epoch [380/1000], Loss: 34033344.3750\n",
      "Epoch [381/1000], Loss: 33756883.1250\n",
      "Epoch [382/1000], Loss: 33506378.6250\n",
      "Epoch [383/1000], Loss: 33227068.2500\n",
      "Epoch [384/1000], Loss: 33020175.7500\n",
      "Epoch [385/1000], Loss: 32727271.6250\n",
      "Epoch [386/1000], Loss: 32469895.5000\n",
      "Epoch [387/1000], Loss: 32219238.1250\n",
      "Epoch [388/1000], Loss: 31948497.6250\n",
      "Epoch [389/1000], Loss: 31721495.0000\n",
      "Epoch [390/1000], Loss: 31463552.6250\n",
      "Epoch [391/1000], Loss: 31240277.1250\n",
      "Epoch [392/1000], Loss: 31028766.7500\n",
      "Epoch [393/1000], Loss: 30765160.3750\n",
      "Epoch [394/1000], Loss: 30514436.0000\n",
      "Epoch [395/1000], Loss: 30294867.0000\n",
      "Epoch [396/1000], Loss: 30072599.6250\n",
      "Epoch [397/1000], Loss: 29829406.7500\n",
      "Epoch [398/1000], Loss: 29587507.0000\n",
      "Epoch [399/1000], Loss: 29370627.7500\n",
      "Epoch [400/1000], Loss: 29137972.7500\n",
      "Epoch [401/1000], Loss: 28930373.7500\n",
      "Epoch [402/1000], Loss: 28692623.7500\n",
      "Epoch [403/1000], Loss: 28478241.5000\n",
      "Epoch [404/1000], Loss: 28243950.2500\n",
      "Epoch [405/1000], Loss: 28087627.1250\n",
      "Epoch [406/1000], Loss: 27846240.0000\n",
      "Epoch [407/1000], Loss: 27648944.1250\n",
      "Epoch [408/1000], Loss: 27432014.1250\n",
      "Epoch [409/1000], Loss: 27215271.8750\n",
      "Epoch [410/1000], Loss: 27045255.7500\n",
      "Epoch [411/1000], Loss: 26806476.5000\n",
      "Epoch [412/1000], Loss: 26602735.5000\n",
      "Epoch [413/1000], Loss: 26414004.8750\n",
      "Epoch [414/1000], Loss: 26192254.0000\n",
      "Epoch [415/1000], Loss: 25989977.5000\n",
      "Epoch [416/1000], Loss: 25806131.8750\n",
      "Epoch [417/1000], Loss: 25607925.6250\n",
      "Epoch [418/1000], Loss: 25413782.3750\n",
      "Epoch [419/1000], Loss: 25218004.2500\n",
      "Epoch [420/1000], Loss: 25019400.3750\n",
      "Epoch [421/1000], Loss: 24852756.6250\n",
      "Epoch [422/1000], Loss: 24655106.7500\n",
      "Epoch [423/1000], Loss: 24466464.1250\n",
      "Epoch [424/1000], Loss: 24271790.8750\n",
      "Epoch [425/1000], Loss: 24111793.6250\n",
      "Epoch [426/1000], Loss: 23939877.5000\n",
      "Epoch [427/1000], Loss: 23740224.5000\n",
      "Epoch [428/1000], Loss: 23557347.6250\n",
      "Epoch [429/1000], Loss: 23371917.7500\n",
      "Epoch [430/1000], Loss: 23254246.8750\n",
      "Epoch [431/1000], Loss: 23046752.8750\n",
      "Epoch [432/1000], Loss: 22882857.8750\n",
      "Epoch [433/1000], Loss: 22733880.6250\n",
      "Epoch [434/1000], Loss: 22553806.2500\n",
      "Epoch [435/1000], Loss: 22377417.7500\n",
      "Epoch [436/1000], Loss: 22206035.3750\n",
      "Epoch [437/1000], Loss: 22045002.3750\n",
      "Epoch [438/1000], Loss: 21876396.0000\n",
      "Epoch [439/1000], Loss: 21689102.8750\n",
      "Epoch [440/1000], Loss: 21559060.5000\n",
      "Epoch [441/1000], Loss: 21400939.2500\n",
      "Epoch [442/1000], Loss: 21254931.2500\n",
      "Epoch [443/1000], Loss: 21077907.7500\n",
      "Epoch [444/1000], Loss: 20918208.8750\n",
      "Epoch [445/1000], Loss: 20783098.1250\n",
      "Epoch [446/1000], Loss: 20614374.5000\n",
      "Epoch [447/1000], Loss: 20449955.7500\n",
      "Epoch [448/1000], Loss: 20309453.3750\n",
      "Epoch [449/1000], Loss: 20178059.2500\n",
      "Epoch [450/1000], Loss: 20050308.3750\n",
      "Epoch [451/1000], Loss: 19870224.6250\n",
      "Epoch [452/1000], Loss: 19723911.5000\n",
      "Epoch [453/1000], Loss: 19593521.8750\n",
      "Epoch [454/1000], Loss: 19462529.7500\n",
      "Epoch [455/1000], Loss: 19331847.3750\n",
      "Epoch [456/1000], Loss: 19164365.3750\n",
      "Epoch [457/1000], Loss: 19038092.5000\n",
      "Epoch [458/1000], Loss: 18886691.3750\n",
      "Epoch [459/1000], Loss: 18767248.6250\n",
      "Epoch [460/1000], Loss: 18634465.2500\n",
      "Epoch [461/1000], Loss: 18483831.1250\n",
      "Epoch [462/1000], Loss: 18364579.1250\n",
      "Epoch [463/1000], Loss: 18230297.5000\n",
      "Epoch [464/1000], Loss: 18088739.4375\n",
      "Epoch [465/1000], Loss: 17959085.4375\n",
      "Epoch [466/1000], Loss: 17826862.6875\n",
      "Epoch [467/1000], Loss: 17722088.3750\n",
      "Epoch [468/1000], Loss: 17591347.8750\n",
      "Epoch [469/1000], Loss: 17492846.1250\n",
      "Epoch [470/1000], Loss: 17353535.1250\n",
      "Epoch [471/1000], Loss: 17214587.5000\n",
      "Epoch [472/1000], Loss: 17097463.2500\n",
      "Epoch [473/1000], Loss: 16966027.8125\n",
      "Epoch [474/1000], Loss: 16854188.8750\n",
      "Epoch [475/1000], Loss: 16742561.3125\n",
      "Epoch [476/1000], Loss: 16621187.7500\n",
      "Epoch [477/1000], Loss: 16491102.8750\n",
      "Epoch [478/1000], Loss: 16386206.1875\n",
      "Epoch [479/1000], Loss: 16287030.8125\n",
      "Epoch [480/1000], Loss: 16155596.0000\n",
      "Epoch [481/1000], Loss: 16049379.5625\n",
      "Epoch [482/1000], Loss: 15957657.5625\n",
      "Epoch [483/1000], Loss: 15832849.8750\n",
      "Epoch [484/1000], Loss: 15727763.0000\n",
      "Epoch [485/1000], Loss: 15613139.0625\n",
      "Epoch [486/1000], Loss: 15494867.1250\n",
      "Epoch [487/1000], Loss: 15392750.5625\n",
      "Epoch [488/1000], Loss: 15283563.5625\n",
      "Epoch [489/1000], Loss: 15194698.6250\n",
      "Epoch [490/1000], Loss: 15098105.6250\n",
      "Epoch [491/1000], Loss: 15005307.5000\n",
      "Epoch [492/1000], Loss: 14878720.5000\n",
      "Epoch [493/1000], Loss: 14770353.3125\n",
      "Epoch [494/1000], Loss: 14682041.1875\n",
      "Epoch [495/1000], Loss: 14586094.3125\n",
      "Epoch [496/1000], Loss: 14497242.8750\n",
      "Epoch [497/1000], Loss: 14385378.5000\n",
      "Epoch [498/1000], Loss: 14293885.2500\n",
      "Epoch [499/1000], Loss: 14202781.6875\n",
      "Epoch [500/1000], Loss: 14098058.3750\n",
      "Epoch [501/1000], Loss: 14010009.6250\n",
      "Epoch [502/1000], Loss: 13916358.6250\n",
      "Epoch [503/1000], Loss: 13816526.2500\n",
      "Epoch [504/1000], Loss: 13732998.9375\n",
      "Epoch [505/1000], Loss: 13649208.1875\n",
      "Epoch [506/1000], Loss: 13557292.5625\n",
      "Epoch [507/1000], Loss: 13476118.3750\n",
      "Epoch [508/1000], Loss: 13379068.7500\n",
      "Epoch [509/1000], Loss: 13285014.8125\n",
      "Epoch [510/1000], Loss: 13205242.6250\n",
      "Epoch [511/1000], Loss: 13106488.5000\n",
      "Epoch [512/1000], Loss: 13038423.0625\n",
      "Epoch [513/1000], Loss: 12950577.2500\n",
      "Epoch [514/1000], Loss: 12854913.5625\n",
      "Epoch [515/1000], Loss: 12779910.1250\n",
      "Epoch [516/1000], Loss: 12698434.0625\n",
      "Epoch [517/1000], Loss: 12617363.5625\n",
      "Epoch [518/1000], Loss: 12522800.9375\n",
      "Epoch [519/1000], Loss: 12471435.4375\n",
      "Epoch [520/1000], Loss: 12383665.3125\n",
      "Epoch [521/1000], Loss: 12306081.1875\n",
      "Epoch [522/1000], Loss: 12225704.6250\n",
      "Epoch [523/1000], Loss: 12140402.3750\n",
      "Epoch [524/1000], Loss: 12059381.8750\n",
      "Epoch [525/1000], Loss: 11989404.6250\n",
      "Epoch [526/1000], Loss: 11923801.2500\n",
      "Epoch [527/1000], Loss: 11839286.3750\n",
      "Epoch [528/1000], Loss: 11762713.8750\n",
      "Epoch [529/1000], Loss: 11691854.3750\n",
      "Epoch [530/1000], Loss: 11627576.8750\n",
      "Epoch [531/1000], Loss: 11563649.1875\n",
      "Epoch [532/1000], Loss: 11479755.4375\n",
      "Epoch [533/1000], Loss: 11414929.7500\n",
      "Epoch [534/1000], Loss: 11348499.3125\n",
      "Epoch [535/1000], Loss: 11290720.1250\n",
      "Epoch [536/1000], Loss: 11207218.6250\n",
      "Epoch [537/1000], Loss: 11151033.6250\n",
      "Epoch [538/1000], Loss: 11066937.2500\n",
      "Epoch [539/1000], Loss: 11007540.3750\n",
      "Epoch [540/1000], Loss: 10938952.2500\n",
      "Epoch [541/1000], Loss: 10872828.6250\n",
      "Epoch [542/1000], Loss: 10810604.5625\n",
      "Epoch [543/1000], Loss: 10750233.2500\n",
      "Epoch [544/1000], Loss: 10684548.2500\n",
      "Epoch [545/1000], Loss: 10629684.0000\n",
      "Epoch [546/1000], Loss: 10551887.1875\n",
      "Epoch [547/1000], Loss: 10489909.3125\n",
      "Epoch [548/1000], Loss: 10447296.3750\n",
      "Epoch [549/1000], Loss: 10374210.3750\n",
      "Epoch [550/1000], Loss: 10313775.1875\n",
      "Epoch [551/1000], Loss: 10258477.6250\n",
      "Epoch [552/1000], Loss: 10191755.5000\n",
      "Epoch [553/1000], Loss: 10135023.8125\n",
      "Epoch [554/1000], Loss: 10086393.6250\n",
      "Epoch [555/1000], Loss: 10027847.0000\n",
      "Epoch [556/1000], Loss: 9958442.1875\n",
      "Epoch [557/1000], Loss: 9912398.6875\n",
      "Epoch [558/1000], Loss: 9851540.6875\n",
      "Epoch [559/1000], Loss: 9805855.1250\n",
      "Epoch [560/1000], Loss: 9753530.0625\n",
      "Epoch [561/1000], Loss: 9691777.5625\n",
      "Epoch [562/1000], Loss: 9650342.5625\n",
      "Epoch [563/1000], Loss: 9593931.8125\n",
      "Epoch [564/1000], Loss: 9530540.5000\n",
      "Epoch [565/1000], Loss: 9478097.0625\n",
      "Epoch [566/1000], Loss: 9434340.5000\n",
      "Epoch [567/1000], Loss: 9381606.7500\n",
      "Epoch [568/1000], Loss: 9323644.8125\n",
      "Epoch [569/1000], Loss: 9280515.8750\n",
      "Epoch [570/1000], Loss: 9225516.6250\n",
      "Epoch [571/1000], Loss: 9182379.8125\n",
      "Epoch [572/1000], Loss: 9136186.1875\n",
      "Epoch [573/1000], Loss: 9083442.0938\n",
      "Epoch [574/1000], Loss: 9025496.5000\n",
      "Epoch [575/1000], Loss: 8981256.0312\n",
      "Epoch [576/1000], Loss: 8934329.3125\n",
      "Epoch [577/1000], Loss: 8898296.5000\n",
      "Epoch [578/1000], Loss: 8849677.2188\n",
      "Epoch [579/1000], Loss: 8794871.2500\n",
      "Epoch [580/1000], Loss: 8758418.3750\n",
      "Epoch [581/1000], Loss: 8707322.9688\n",
      "Epoch [582/1000], Loss: 8663133.2188\n",
      "Epoch [583/1000], Loss: 8613399.8750\n",
      "Epoch [584/1000], Loss: 8578131.1875\n",
      "Epoch [585/1000], Loss: 8532788.9062\n",
      "Epoch [586/1000], Loss: 8489360.4062\n",
      "Epoch [587/1000], Loss: 8452083.3438\n",
      "Epoch [588/1000], Loss: 8402648.2812\n",
      "Epoch [589/1000], Loss: 8366111.1250\n",
      "Epoch [590/1000], Loss: 8329024.6250\n",
      "Epoch [591/1000], Loss: 8285715.7188\n",
      "Epoch [592/1000], Loss: 8241546.5000\n",
      "Epoch [593/1000], Loss: 8205813.0938\n",
      "Epoch [594/1000], Loss: 8154116.0000\n",
      "Epoch [595/1000], Loss: 8128328.6250\n",
      "Epoch [596/1000], Loss: 8086879.3125\n",
      "Epoch [597/1000], Loss: 8045661.0312\n",
      "Epoch [598/1000], Loss: 8014242.1250\n",
      "Epoch [599/1000], Loss: 7970428.9375\n",
      "Epoch [600/1000], Loss: 7935895.9688\n",
      "Epoch [601/1000], Loss: 7894522.5312\n",
      "Epoch [602/1000], Loss: 7855825.0938\n",
      "Epoch [603/1000], Loss: 7822724.6250\n",
      "Epoch [604/1000], Loss: 7792713.6562\n",
      "Epoch [605/1000], Loss: 7761019.3750\n",
      "Epoch [606/1000], Loss: 7720364.9062\n",
      "Epoch [607/1000], Loss: 7681564.9375\n",
      "Epoch [608/1000], Loss: 7649835.0000\n",
      "Epoch [609/1000], Loss: 7616680.5625\n",
      "Epoch [610/1000], Loss: 7585045.3438\n",
      "Epoch [611/1000], Loss: 7547151.2812\n",
      "Epoch [612/1000], Loss: 7516846.8750\n",
      "Epoch [613/1000], Loss: 7474182.7500\n",
      "Epoch [614/1000], Loss: 7453628.8125\n",
      "Epoch [615/1000], Loss: 7414307.9062\n",
      "Epoch [616/1000], Loss: 7382105.1562\n",
      "Epoch [617/1000], Loss: 7355483.5000\n",
      "Epoch [618/1000], Loss: 7331567.6250\n",
      "Epoch [619/1000], Loss: 7285094.1875\n",
      "Epoch [620/1000], Loss: 7253650.0312\n",
      "Epoch [621/1000], Loss: 7222439.2812\n",
      "Epoch [622/1000], Loss: 7205435.4375\n",
      "Epoch [623/1000], Loss: 7160336.5312\n",
      "Epoch [624/1000], Loss: 7136588.8125\n",
      "Epoch [625/1000], Loss: 7110146.8438\n",
      "Epoch [626/1000], Loss: 7078424.2500\n",
      "Epoch [627/1000], Loss: 7044107.8438\n",
      "Epoch [628/1000], Loss: 7026912.9062\n",
      "Epoch [629/1000], Loss: 6997462.1562\n",
      "Epoch [630/1000], Loss: 6964039.1562\n",
      "Epoch [631/1000], Loss: 6938567.9688\n",
      "Epoch [632/1000], Loss: 6905051.7812\n",
      "Epoch [633/1000], Loss: 6882795.6875\n",
      "Epoch [634/1000], Loss: 6854715.3125\n",
      "Epoch [635/1000], Loss: 6833936.0312\n",
      "Epoch [636/1000], Loss: 6801115.2812\n",
      "Epoch [637/1000], Loss: 6778519.3438\n",
      "Epoch [638/1000], Loss: 6748125.3125\n",
      "Epoch [639/1000], Loss: 6728103.5312\n",
      "Epoch [640/1000], Loss: 6702193.1875\n",
      "Epoch [641/1000], Loss: 6683520.9062\n",
      "Epoch [642/1000], Loss: 6651901.3750\n",
      "Epoch [643/1000], Loss: 6632995.5938\n",
      "Epoch [644/1000], Loss: 6598002.4375\n",
      "Epoch [645/1000], Loss: 6574299.6250\n",
      "Epoch [646/1000], Loss: 6546822.7188\n",
      "Epoch [647/1000], Loss: 6533931.4375\n",
      "Epoch [648/1000], Loss: 6510541.6875\n",
      "Epoch [649/1000], Loss: 6493634.4688\n",
      "Epoch [650/1000], Loss: 6464767.2812\n",
      "Epoch [651/1000], Loss: 6431603.7500\n",
      "Epoch [652/1000], Loss: 6421228.6250\n",
      "Epoch [653/1000], Loss: 6394445.1875\n",
      "Epoch [654/1000], Loss: 6379952.5000\n",
      "Epoch [655/1000], Loss: 6352211.3125\n",
      "Epoch [656/1000], Loss: 6332781.8125\n",
      "Epoch [657/1000], Loss: 6303888.1250\n",
      "Epoch [658/1000], Loss: 6291123.8125\n",
      "Epoch [659/1000], Loss: 6258551.3438\n",
      "Epoch [660/1000], Loss: 6247312.5312\n",
      "Epoch [661/1000], Loss: 6227967.7500\n",
      "Epoch [662/1000], Loss: 6208249.6250\n",
      "Epoch [663/1000], Loss: 6189253.4062\n",
      "Epoch [664/1000], Loss: 6155920.3438\n",
      "Epoch [665/1000], Loss: 6145080.2500\n",
      "Epoch [666/1000], Loss: 6130098.2812\n",
      "Epoch [667/1000], Loss: 6103995.7812\n",
      "Epoch [668/1000], Loss: 6082726.9375\n",
      "Epoch [669/1000], Loss: 6072974.6875\n",
      "Epoch [670/1000], Loss: 6056530.9375\n",
      "Epoch [671/1000], Loss: 6037732.5312\n",
      "Epoch [672/1000], Loss: 6009678.3438\n",
      "Epoch [673/1000], Loss: 5994466.8438\n",
      "Epoch [674/1000], Loss: 5985465.2188\n",
      "Epoch [675/1000], Loss: 5962779.5000\n",
      "Epoch [676/1000], Loss: 5942103.1562\n",
      "Epoch [677/1000], Loss: 5919077.3125\n",
      "Epoch [678/1000], Loss: 5905550.0938\n",
      "Epoch [679/1000], Loss: 5892180.9062\n",
      "Epoch [680/1000], Loss: 5881757.3438\n",
      "Epoch [681/1000], Loss: 5852123.5000\n",
      "Epoch [682/1000], Loss: 5839147.9375\n",
      "Epoch [683/1000], Loss: 5823093.7500\n",
      "Epoch [684/1000], Loss: 5809906.6250\n",
      "Epoch [685/1000], Loss: 5792673.2812\n",
      "Epoch [686/1000], Loss: 5777803.5938\n",
      "Epoch [687/1000], Loss: 5758293.6562\n",
      "Epoch [688/1000], Loss: 5741048.4062\n",
      "Epoch [689/1000], Loss: 5736838.2812\n",
      "Epoch [690/1000], Loss: 5717221.9688\n",
      "Epoch [691/1000], Loss: 5699108.1875\n",
      "Epoch [692/1000], Loss: 5684056.1562\n",
      "Epoch [693/1000], Loss: 5674152.2188\n",
      "Epoch [694/1000], Loss: 5657072.5312\n",
      "Epoch [695/1000], Loss: 5643105.8750\n",
      "Epoch [696/1000], Loss: 5624521.0625\n",
      "Epoch [697/1000], Loss: 5620209.1250\n",
      "Epoch [698/1000], Loss: 5602329.2812\n",
      "Epoch [699/1000], Loss: 5588714.0938\n",
      "Epoch [700/1000], Loss: 5576138.5938\n",
      "Epoch [701/1000], Loss: 5560817.7500\n",
      "Epoch [702/1000], Loss: 5548396.8750\n",
      "Epoch [703/1000], Loss: 5531939.2500\n",
      "Epoch [704/1000], Loss: 5521142.0312\n",
      "Epoch [705/1000], Loss: 5507051.0938\n",
      "Epoch [706/1000], Loss: 5493031.8750\n",
      "Epoch [707/1000], Loss: 5477771.5000\n",
      "Epoch [708/1000], Loss: 5473358.6562\n",
      "Epoch [709/1000], Loss: 5462448.3750\n",
      "Epoch [710/1000], Loss: 5442834.2188\n",
      "Epoch [711/1000], Loss: 5433558.8438\n",
      "Epoch [712/1000], Loss: 5417737.3125\n",
      "Epoch [713/1000], Loss: 5404050.5625\n",
      "Epoch [714/1000], Loss: 5394923.0312\n",
      "Epoch [715/1000], Loss: 5385875.9688\n",
      "Epoch [716/1000], Loss: 5366387.7500\n",
      "Epoch [717/1000], Loss: 5356120.4062\n",
      "Epoch [718/1000], Loss: 5349821.3438\n",
      "Epoch [719/1000], Loss: 5339682.0625\n",
      "Epoch [720/1000], Loss: 5327488.2500\n",
      "Epoch [721/1000], Loss: 5314623.4062\n",
      "Epoch [722/1000], Loss: 5301809.4062\n",
      "Epoch [723/1000], Loss: 5292611.7812\n",
      "Epoch [724/1000], Loss: 5283372.3750\n",
      "Epoch [725/1000], Loss: 5272996.4062\n",
      "Epoch [726/1000], Loss: 5257487.9688\n",
      "Epoch [727/1000], Loss: 5251395.5000\n",
      "Epoch [728/1000], Loss: 5244051.2500\n",
      "Epoch [729/1000], Loss: 5229816.9062\n",
      "Epoch [730/1000], Loss: 5224814.0625\n",
      "Epoch [731/1000], Loss: 5202554.5625\n",
      "Epoch [732/1000], Loss: 5199114.8438\n",
      "Epoch [733/1000], Loss: 5189770.3125\n",
      "Epoch [734/1000], Loss: 5188300.6250\n",
      "Epoch [735/1000], Loss: 5172476.3125\n",
      "Epoch [736/1000], Loss: 5160508.1562\n",
      "Epoch [737/1000], Loss: 5158621.1250\n",
      "Epoch [738/1000], Loss: 5147876.5625\n",
      "Epoch [739/1000], Loss: 5137399.7500\n",
      "Epoch [740/1000], Loss: 5124176.3438\n",
      "Epoch [741/1000], Loss: 5116225.2812\n",
      "Epoch [742/1000], Loss: 5109672.6875\n",
      "Epoch [743/1000], Loss: 5098776.5000\n",
      "Epoch [744/1000], Loss: 5093184.0938\n",
      "Epoch [745/1000], Loss: 5087343.9688\n",
      "Epoch [746/1000], Loss: 5076357.3125\n",
      "Epoch [747/1000], Loss: 5065867.2812\n",
      "Epoch [748/1000], Loss: 5056466.6875\n",
      "Epoch [749/1000], Loss: 5054416.8750\n",
      "Epoch [750/1000], Loss: 5041666.0312\n",
      "Epoch [751/1000], Loss: 5036772.0625\n",
      "Epoch [752/1000], Loss: 5018846.6875\n",
      "Epoch [753/1000], Loss: 5013818.3750\n",
      "Epoch [754/1000], Loss: 5012789.1250\n",
      "Epoch [755/1000], Loss: 5006924.9375\n",
      "Epoch [756/1000], Loss: 5001111.1250\n",
      "Epoch [757/1000], Loss: 4990682.3438\n",
      "Epoch [758/1000], Loss: 4985169.0938\n",
      "Epoch [759/1000], Loss: 4976670.4688\n",
      "Epoch [760/1000], Loss: 4967688.0312\n",
      "Epoch [761/1000], Loss: 4958069.2188\n",
      "Epoch [762/1000], Loss: 4954182.3750\n",
      "Epoch [763/1000], Loss: 4948252.2188\n",
      "Epoch [764/1000], Loss: 4944760.7500\n",
      "Epoch [765/1000], Loss: 4933005.5000\n",
      "Epoch [766/1000], Loss: 4930895.3438\n",
      "Epoch [767/1000], Loss: 4918534.2812\n",
      "Epoch [768/1000], Loss: 4913625.3750\n",
      "Epoch [769/1000], Loss: 4908826.3750\n",
      "Epoch [770/1000], Loss: 4902187.5000\n",
      "Epoch [771/1000], Loss: 4890679.1875\n",
      "Epoch [772/1000], Loss: 4886858.4062\n",
      "Epoch [773/1000], Loss: 4883384.5312\n",
      "Epoch [774/1000], Loss: 4875415.3750\n",
      "Epoch [775/1000], Loss: 4871750.5000\n",
      "Epoch [776/1000], Loss: 4863567.3438\n",
      "Epoch [777/1000], Loss: 4856390.5625\n",
      "Epoch [778/1000], Loss: 4851922.1875\n",
      "Epoch [779/1000], Loss: 4841376.9688\n",
      "Epoch [780/1000], Loss: 4839150.2812\n",
      "Epoch [781/1000], Loss: 4835264.0625\n",
      "Epoch [782/1000], Loss: 4827873.6250\n",
      "Epoch [783/1000], Loss: 4823906.1875\n",
      "Epoch [784/1000], Loss: 4817451.4688\n",
      "Epoch [785/1000], Loss: 4809346.1875\n",
      "Epoch [786/1000], Loss: 4805699.4375\n",
      "Epoch [787/1000], Loss: 4799865.0000\n",
      "Epoch [788/1000], Loss: 4794122.9688\n",
      "Epoch [789/1000], Loss: 4789098.8438\n",
      "Epoch [790/1000], Loss: 4782548.5625\n",
      "Epoch [791/1000], Loss: 4784183.4375\n",
      "Epoch [792/1000], Loss: 4772989.1250\n",
      "Epoch [793/1000], Loss: 4768157.7812\n",
      "Epoch [794/1000], Loss: 4759787.6875\n",
      "Epoch [795/1000], Loss: 4760714.4688\n",
      "Epoch [796/1000], Loss: 4756407.0938\n",
      "Epoch [797/1000], Loss: 4748744.0312\n",
      "Epoch [798/1000], Loss: 4743928.6250\n",
      "Epoch [799/1000], Loss: 4743662.0938\n",
      "Epoch [800/1000], Loss: 4739034.7500\n",
      "Epoch [801/1000], Loss: 4731223.5000\n",
      "Epoch [802/1000], Loss: 4726670.3125\n",
      "Epoch [803/1000], Loss: 4723619.8125\n",
      "Epoch [804/1000], Loss: 4720648.5938\n",
      "Epoch [805/1000], Loss: 4714123.4375\n",
      "Epoch [806/1000], Loss: 4710267.5938\n",
      "Epoch [807/1000], Loss: 4703508.3438\n",
      "Epoch [808/1000], Loss: 4698997.8438\n",
      "Epoch [809/1000], Loss: 4699075.5312\n",
      "Epoch [810/1000], Loss: 4693865.6562\n",
      "Epoch [811/1000], Loss: 4687907.1250\n",
      "Epoch [812/1000], Loss: 4683223.8125\n",
      "Epoch [813/1000], Loss: 4680051.6562\n",
      "Epoch [814/1000], Loss: 4677127.6875\n",
      "Epoch [815/1000], Loss: 4674156.7188\n",
      "Epoch [816/1000], Loss: 4669227.9375\n",
      "Epoch [817/1000], Loss: 4665524.5625\n",
      "Epoch [818/1000], Loss: 4660135.1562\n",
      "Epoch [819/1000], Loss: 4655737.8125\n",
      "Epoch [820/1000], Loss: 4655560.4062\n",
      "Epoch [821/1000], Loss: 4643383.0312\n",
      "Epoch [822/1000], Loss: 4650745.9375\n",
      "Epoch [823/1000], Loss: 4647177.5000\n",
      "Epoch [824/1000], Loss: 4643697.9688\n",
      "Epoch [825/1000], Loss: 4636633.1562\n",
      "Epoch [826/1000], Loss: 4634492.1562\n",
      "Epoch [827/1000], Loss: 4629626.7812\n",
      "Epoch [828/1000], Loss: 4632052.7812\n",
      "Epoch [829/1000], Loss: 4623286.2812\n",
      "Epoch [830/1000], Loss: 4619910.5312\n",
      "Epoch [831/1000], Loss: 4612443.7500\n",
      "Epoch [832/1000], Loss: 4615434.8438\n",
      "Epoch [833/1000], Loss: 4611393.4062\n",
      "Epoch [834/1000], Loss: 4606932.6875\n",
      "Epoch [835/1000], Loss: 4601798.0312\n",
      "Epoch [836/1000], Loss: 4599835.9688\n",
      "Epoch [837/1000], Loss: 4597259.3125\n",
      "Epoch [838/1000], Loss: 4593407.8438\n",
      "Epoch [839/1000], Loss: 4592159.4688\n",
      "Epoch [840/1000], Loss: 4587558.3750\n",
      "Epoch [841/1000], Loss: 4585397.1875\n",
      "Epoch [842/1000], Loss: 4584545.4062\n",
      "Epoch [843/1000], Loss: 4583576.7500\n",
      "Epoch [844/1000], Loss: 4580646.6250\n",
      "Epoch [845/1000], Loss: 4575095.1562\n",
      "Epoch [846/1000], Loss: 4572609.6875\n",
      "Epoch [847/1000], Loss: 4568837.9062\n",
      "Epoch [848/1000], Loss: 4563885.1562\n",
      "Epoch [849/1000], Loss: 4564127.0938\n",
      "Epoch [850/1000], Loss: 4563980.5000\n",
      "Epoch [851/1000], Loss: 4560127.8750\n",
      "Epoch [852/1000], Loss: 4557646.6875\n",
      "Epoch [853/1000], Loss: 4552564.8438\n",
      "Epoch [854/1000], Loss: 4552133.7500\n",
      "Epoch [855/1000], Loss: 4548021.4062\n",
      "Epoch [856/1000], Loss: 4545514.0312\n",
      "Epoch [857/1000], Loss: 4547662.4062\n",
      "Epoch [858/1000], Loss: 4540153.9375\n",
      "Epoch [859/1000], Loss: 4539772.3125\n",
      "Epoch [860/1000], Loss: 4537326.5000\n",
      "Epoch [861/1000], Loss: 4538635.0625\n",
      "Epoch [862/1000], Loss: 4533558.7812\n",
      "Epoch [863/1000], Loss: 4531547.6250\n",
      "Epoch [864/1000], Loss: 4528465.3438\n",
      "Epoch [865/1000], Loss: 4525831.9219\n",
      "Epoch [866/1000], Loss: 4525302.3750\n",
      "Epoch [867/1000], Loss: 4523054.6250\n",
      "Epoch [868/1000], Loss: 4519529.2500\n",
      "Epoch [869/1000], Loss: 4517100.5938\n",
      "Epoch [870/1000], Loss: 4513059.8125\n",
      "Epoch [871/1000], Loss: 4514743.6406\n",
      "Epoch [872/1000], Loss: 4509210.0938\n",
      "Epoch [873/1000], Loss: 4512952.5312\n",
      "Epoch [874/1000], Loss: 4506383.1094\n",
      "Epoch [875/1000], Loss: 4506925.7188\n",
      "Epoch [876/1000], Loss: 4504404.7031\n",
      "Epoch [877/1000], Loss: 4501618.6875\n",
      "Epoch [878/1000], Loss: 4499082.9062\n",
      "Epoch [879/1000], Loss: 4495379.6406\n",
      "Epoch [880/1000], Loss: 4495033.0781\n",
      "Epoch [881/1000], Loss: 4492785.4062\n",
      "Epoch [882/1000], Loss: 4492892.2656\n",
      "Epoch [883/1000], Loss: 4493147.3438\n",
      "Epoch [884/1000], Loss: 4491367.5000\n",
      "Epoch [885/1000], Loss: 4488582.6875\n",
      "Epoch [886/1000], Loss: 4487257.2188\n",
      "Epoch [887/1000], Loss: 4485780.1562\n",
      "Epoch [888/1000], Loss: 4486022.8125\n",
      "Epoch [889/1000], Loss: 4483571.6562\n",
      "Epoch [890/1000], Loss: 4481065.8281\n",
      "Epoch [891/1000], Loss: 4478429.1875\n",
      "Epoch [892/1000], Loss: 4477254.0625\n",
      "Epoch [893/1000], Loss: 4479149.6250\n",
      "Epoch [894/1000], Loss: 4477313.5156\n",
      "Epoch [895/1000], Loss: 4470767.8750\n",
      "Epoch [896/1000], Loss: 4470296.7500\n",
      "Epoch [897/1000], Loss: 4468464.2188\n",
      "Epoch [898/1000], Loss: 4464595.4688\n",
      "Epoch [899/1000], Loss: 4465015.7031\n",
      "Epoch [900/1000], Loss: 4463099.7500\n",
      "Epoch [901/1000], Loss: 4460962.3438\n",
      "Epoch [902/1000], Loss: 4464686.8125\n",
      "Epoch [903/1000], Loss: 4460584.2969\n",
      "Epoch [904/1000], Loss: 4460512.2500\n",
      "Epoch [905/1000], Loss: 4455129.7969\n",
      "Epoch [906/1000], Loss: 4457629.1875\n",
      "Epoch [907/1000], Loss: 4453963.8281\n",
      "Epoch [908/1000], Loss: 4454716.0469\n",
      "Epoch [909/1000], Loss: 4451782.3438\n",
      "Epoch [910/1000], Loss: 4449549.0312\n",
      "Epoch [911/1000], Loss: 4452387.1562\n",
      "Epoch [912/1000], Loss: 4450733.2344\n",
      "Epoch [913/1000], Loss: 4451482.3438\n",
      "Epoch [914/1000], Loss: 4449037.4688\n",
      "Epoch [915/1000], Loss: 4447788.7656\n",
      "Epoch [916/1000], Loss: 4444427.2500\n",
      "Epoch [917/1000], Loss: 4442774.9844\n",
      "Epoch [918/1000], Loss: 4442493.6406\n",
      "Epoch [919/1000], Loss: 4438168.3594\n",
      "Epoch [920/1000], Loss: 4437733.0469\n",
      "Epoch [921/1000], Loss: 4440843.2500\n",
      "Epoch [922/1000], Loss: 4437262.8750\n",
      "Epoch [923/1000], Loss: 4437727.4844\n",
      "Epoch [924/1000], Loss: 4434684.2656\n",
      "Epoch [925/1000], Loss: 4436088.8281\n",
      "Epoch [926/1000], Loss: 4431716.6406\n",
      "Epoch [927/1000], Loss: 4432317.6406\n",
      "Epoch [928/1000], Loss: 4432608.9688\n",
      "Epoch [929/1000], Loss: 4429772.4531\n",
      "Epoch [930/1000], Loss: 4429516.7500\n",
      "Epoch [931/1000], Loss: 4427107.3125\n",
      "Epoch [932/1000], Loss: 4428388.8594\n",
      "Epoch [933/1000], Loss: 4429186.6406\n",
      "Epoch [934/1000], Loss: 4427551.1250\n",
      "Epoch [935/1000], Loss: 4427774.7188\n",
      "Epoch [936/1000], Loss: 4424248.0469\n",
      "Epoch [937/1000], Loss: 4424990.9219\n",
      "Epoch [938/1000], Loss: 4421872.4219\n",
      "Epoch [939/1000], Loss: 4421444.5000\n",
      "Epoch [940/1000], Loss: 4420781.6719\n",
      "Epoch [941/1000], Loss: 4419712.8125\n",
      "Epoch [942/1000], Loss: 4419769.4844\n",
      "Epoch [943/1000], Loss: 4417179.5625\n",
      "Epoch [944/1000], Loss: 4417910.8594\n",
      "Epoch [945/1000], Loss: 4416685.0938\n",
      "Epoch [946/1000], Loss: 4414585.0312\n",
      "Epoch [947/1000], Loss: 4416717.2656\n",
      "Epoch [948/1000], Loss: 4415812.0469\n",
      "Epoch [949/1000], Loss: 4413418.9688\n",
      "Epoch [950/1000], Loss: 4412569.3750\n",
      "Epoch [951/1000], Loss: 4411223.5625\n",
      "Epoch [952/1000], Loss: 4409723.5781\n",
      "Epoch [953/1000], Loss: 4409811.7656\n",
      "Epoch [954/1000], Loss: 4408316.6406\n",
      "Epoch [955/1000], Loss: 4408624.8594\n",
      "Epoch [956/1000], Loss: 4409170.5156\n",
      "Epoch [957/1000], Loss: 4406056.6719\n",
      "Epoch [958/1000], Loss: 4408153.3125\n",
      "Epoch [959/1000], Loss: 4408710.1562\n",
      "Epoch [960/1000], Loss: 4405819.4844\n",
      "Epoch [961/1000], Loss: 4400586.9219\n",
      "Epoch [962/1000], Loss: 4406609.1094\n",
      "Epoch [963/1000], Loss: 4406175.2031\n",
      "Epoch [964/1000], Loss: 4401552.9062\n",
      "Epoch [965/1000], Loss: 4401222.8125\n",
      "Epoch [966/1000], Loss: 4400420.0156\n",
      "Epoch [967/1000], Loss: 4401742.3281\n",
      "Epoch [968/1000], Loss: 4401087.5781\n",
      "Epoch [969/1000], Loss: 4399196.2969\n",
      "Epoch [970/1000], Loss: 4396768.2188\n",
      "Epoch [971/1000], Loss: 4394784.5156\n",
      "Epoch [972/1000], Loss: 4395898.7031\n",
      "Epoch [973/1000], Loss: 4396133.3125\n",
      "Epoch [974/1000], Loss: 4400530.2500\n",
      "Epoch [975/1000], Loss: 4395948.8125\n",
      "Epoch [976/1000], Loss: 4397460.3438\n",
      "Epoch [977/1000], Loss: 4397821.2812\n",
      "Epoch [978/1000], Loss: 4397491.5469\n",
      "Epoch [979/1000], Loss: 4395870.7969\n",
      "Epoch [980/1000], Loss: 4396828.8906\n",
      "Epoch [981/1000], Loss: 4394093.4844\n",
      "Epoch [982/1000], Loss: 4393559.7188\n",
      "Epoch [983/1000], Loss: 4394656.0156\n",
      "Epoch [984/1000], Loss: 4392833.7500\n",
      "Epoch [985/1000], Loss: 4390906.1406\n",
      "Epoch [986/1000], Loss: 4390442.7344\n",
      "Epoch [987/1000], Loss: 4389366.3281\n",
      "Epoch [988/1000], Loss: 4390026.9062\n",
      "Epoch [989/1000], Loss: 4389660.8438\n",
      "Epoch [990/1000], Loss: 4392871.4531\n",
      "Epoch [991/1000], Loss: 4388578.1406\n",
      "Epoch [992/1000], Loss: 4388201.6406\n",
      "Epoch [993/1000], Loss: 4386339.8750\n",
      "Epoch [994/1000], Loss: 4386265.5938\n",
      "Epoch [995/1000], Loss: 4390215.4062\n",
      "Epoch [996/1000], Loss: 4386682.5781\n",
      "Epoch [997/1000], Loss: 4384610.6406\n",
      "Epoch [998/1000], Loss: 4386735.8906\n",
      "Epoch [999/1000], Loss: 4383652.8125\n",
      "Epoch [1000/1000], Loss: 4383737.2344\n"
     ]
    }
   ],
   "source": [
    "VAD_best = VAD_LogNormal(latent_dim=128, device=device)\n",
    "trainer_best = VAD_Trainer(var_decoder=VAD_best, dataloader=train_dl, latent_dim=128, beta=5e6, device=device, lr=0.001)\n",
    "_ = trainer_best.train(num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edda5b7e-e9d7-4b24-b253-566316440be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31134651973843575\n"
     ]
    }
   ],
   "source": [
    "num_test_samples = len(train_dl.dataset)\n",
    "opt = optim.Adam([trainer_best.latents], lr=1e-3)\n",
    "evaluate_loss = evaluate_model(model=VAD_best, test_dl=train_dl, opt=opt, latents=trainer_best.latents, epochs=1000, device=device)\n",
    "print(evaluate_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9360261-02b1-4d2c-96b3-c102c9c66b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "latents = VAD_best.reparameterize(trainer_best.latents)\n",
    "utils.plot_tsne(train_ds, latents, f\"tsne_LogNormal_best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95bd661-ea43-4e60-93f0-cade1c016a2f",
   "metadata": {},
   "source": [
    "## Sample specific vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc2bfd32-1c89-4f4f-9494-9d7f6e7adc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = len(test_dl.dataset)\n",
    "mu_test = torch.randn(num_test_samples, VAD_best.latent_dim, device=device, requires_grad=True)\n",
    "sigma_test = torch.randn(num_test_samples, VAD_best.latent_dim, device=device, requires_grad=True)\n",
    "test_latents = torch.nn.parameter.Parameter(torch.stack([mu_test, sigma_test], dim=1)).to(device)\n",
    "opt = optim.Adam([test_latents], lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6568406b-c6c5-40af-9339-9825107b7bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AD has finished test evaluation with a test loss of 0.31502133049070835.\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluate_model(model=VAD_best, test_dl=test_dl, opt=opt, latents=test_latents, epochs=1000, device=device)\n",
    "print(f\"AD has finished test evaluation with a test loss of {test_loss}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a5d3b54-cf39-4e45-af3f-8a573b9b3007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_test_latents = VAD_best.reparameterize(test_latents)\n",
    "utils.plot_tsne(test_ds, final_test_latents, f\"tsne_test_LogNormal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad556234-27db-4273-b409-cc4d0380268a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(49)\n",
    "sampled_indices = random.sample(range(1000), 5)\n",
    "random_latents_tensor = torch.randn(5,VAD_best.latent_dim, device=device)\n",
    "\n",
    "\n",
    "sampled_test_images = VAD_best(test_latents[sampled_indices]).view(-1, 1, 28, 28)\n",
    "random_test_images = VAD_best.decoder(random_latents_tensor).view(-1, 1, 28, 28)\n",
    "\n",
    "utils.save_images(sampled_test_images, \"sampled_test_images_VAD_LogNormal.png\")\n",
    "utils.save_images(random_test_images, \"random_test_images_VAD_LogNormal.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787e7d41-cb83-46b6-95b0-33a7258e5fee",
   "metadata": {},
   "source": [
    "## Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e96f6f8-17b2-40b8-8f4e-4b8998ad729a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sampled_indices = [1, 25]\n",
    "sampled_latents = [final_test_latents[i] for i in sampled_indices]\n",
    "weights = np.linspace(0, 1, 7)\n",
    "interpolated_latents = [w * sampled_latents[0] + (1 - w) * sampled_latents[1] for w in weights]\n",
    "interpolated_latents_tensor = torch.stack(interpolated_latents)\n",
    "interpolated_images = VAD_best.decoder(interpolated_latents_tensor).view(-1, 1, 28, 28)\n",
    "utils.save_images(interpolated_images, \"interpolated_images_VAD_LogNormal.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
